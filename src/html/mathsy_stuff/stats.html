<!DOCTYPE html>
<html lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <!-- HTML 4 -->
	<meta charset="UTF-8">                                              <!-- HTML 5 -->
	<title>Statistics notes</title>
	<!-- META_INSERT -->
	<link rel="stylesheet" href="../jeh-monolith.css" type="text/css" />
	<script src="../jeh-monolith.js"></script>
   <!-- MATHJAX -->
  <!--
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			tex2jax: {
				inlineMath: [['$','$'], ['\\(','\\)']]
			},
			displayAlign: "left",
			displayIndent: "2em"
		});
	</script>
	<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
	<style>
		ul li .MathJax {font-size: 3em;}
	</style>

	<script>
	MathJax.Hub.Queue(function () {
		$("#dialog").dialog("close")
	});

	$(function(){
		$("#dialog").dialog({ autoOpen: false, resizable: false });
		$('#dialog').parent().css({position:"fixed"}).end().dialog('open');

      $("#confidence_interval_illustration_code_p").hide();
      $("#z_confidence_interval_illustration_code_p").hide();

      $("#confidence_interval_illustration_code_link").click(function () {
         $("#confidence_interval_illustration_code_p").toggle();
      });
      $("#z_confidence_interval_illustration_code_link").click(function () {
         $("#z_confidence_interval_illustration_code_p").toggle();
      });
	});
  </script>
  -->
  <style type="text/css">
      .noborder {
         border: 0px;
      }

      table.dataDefTable tr > td:first-child {
         font-weight: bold;
      }

      table.allborders {
         border: 1px solid lightblue;
      }

      table.allborders tr td {
         border: 1px solid lightblue;
      }

      td.selcell {
         background: lightblue;
      }

      del {
         color: gray;
      }

   </style>
</head>

<body>
<div id="header">
   -- This is JEHTech --
</div>

<!--
<div id="dialog" title="Page still rendering...">
	<table style="width: 100%; margin: 0px; padding: 0px; border: 0px;">
		<tr>
			<td style="vertical-align:bottom !important; padding:0px; margin: 0px; width:60px;">
				<img src="../images/jeh-tech/loading_animation.gif" style="width:50px; height:50px;">
			</td>
			<td>
				MathJax is busy rendering this page. Dialog will auto-close when ready. Please wait...
			</td>
		</tr>
	</table>
</div>
-->

<div id="sidebar">
   <h1 class="title">Links...</h1>
   <div id="includedContent"></div>
</div>

<div id="content">
   <h1 class="title">Statistics Notes</h1>
   <p>
   </p>
   <h2>Page Contents</h2>
   <div id="page_contents">
   </div>

<h2>References and Resources</h2>
<div>
   <ol>
      <li><p>&quot;Introduction To Statistics&quot;, Thanos Margoupis, University of Bath, Peason Custom Publishing.</p>
          <p>A technical book but quite dry (as most statistics books are!)</p>
      </li>
      <li><p>&quot;An Adventure In Statistics, The Reality Enigma&quot;, Andy Field</p>
          <p>A very entertaining book that explains statistics in a really intuitive way and uses examples that are
             actually slightly interesting!</p>
      </li>
   </ol>
   <p>
      The following are absolutely amazing, completely free, well taught resources
      that just put things in plain English and make concepts that much easier
      to understand! Definitely worth a look!
   </p>
   <ol>
      <li>The amazing <a href="https://www.khanacademy.org/math" target="_blank">Khan Achademy</a>.</li>
      <li>The amazing <a href="https://www.ck12.org" target="_blank">CK12 Foundation</a>.</li>
   </ol>
</div>


<h2>The Basics of Discrete Probability Distributions</h2>
<div>
   <h3>Some Terminology</h3>
   <h4>Variables...</h4>
   <table class="dataDefTable noborder">
      <tbody>
         <tr><td>Categorical Variable</td>
            <td>Discrete variable which can be one of a set of such as the anwer
               to a YES/NO question: the variable can be either YES or NO. Or the
               answer to a quality question where the choices are good, ambivalent
               or bad, for example.
            </td>
         </tr>
         <tr><td>Consistent estimator</td>
            <td>A consistent estimator is one that converges to the value being
               estimated.
            </td>
         </tr>
         <tr><td>Numerical Variable</td>
            <td>Has a value from a set of numbers. That set can be continuous,
               like the set of real numbers, or discrete like the set of
               integers.
            </td>
         </tr>
         <tr>
            <td>Random Variable</td>
            <td>The numerical outcome of a random experiment. <em>Discrete</em> if it
                  can take on more than a countable number of values. <em>Continuous </em>
                  if it can take any value over an uncountable range.
            </td>
         </tr>
         <tr>
            <td>I.D.D.</td>
            <td>A sequence or other collection of random variables is independent
               and <b>identically distributed (i.i.d.)</b> if each random variable
               has the same probability distribution as the others and all are
               mutually independent.
            </td>
         </tr>
         <tr><td>Qualitative Data</td>
            <td>Data where there is no measurable difference (in a quantitative
               sense) between two values (that makes sense). For example, the colour of a car.
               The car can be &quot;nice&quot; or &quot;sporty&quot;, but we
               can't define the the difference in terms of a number like 4.83,
               for example.
            </td>
         </tr>
         <tr><td>Quantitative Data</td>
            <td>Data is numerical and the difference between data is a
               well defined notion. For example, if car A goes 33 MPG and
               care B does, 40 MPG, then we can say the difference is 7MPG.
            </td>
         </tr>
         <tr><td>Ordinal Data</td>
            <td>The value of the data has an order with respect to other
               possible values.
            </td>
         </tr>
      </tbody>
   </table>

   <h4>Populations and samples...</h4>
   <p>It is always worth keeping in mind that <b>probability is a measure
      describing the likelihood of an event from the <u>population</u></b>.
      It is <em>not</em> &quot;in&quot; the data set (or sample)
      obtained... a sample is user to <em>infer</em> a probability about a
      population parameter.
   </p>
   <table class="dataDefTable noborder">
      <tbody>
         <tr><td>Population</td>
            <td>The complete set of items of interest.
               Size is very large, denoted <i>N</i>, possibly infinite.
               Population is the entire pool from which a statistical sample is draw.
            </td>
         </tr>
         <tr><td>Sample</td>
            <td>An observed subset of the population. Size denoted <i>n</i>.
            </td>
         </tr>
         <tr><td>Random Sampling</td>
            <td>Select <i>n</i> objects from population such that each object
               is equally likely to be chosen. Selecting 1 object does not
               influence the selection of the next. Selection is utterly
               by chance.
            </td>
         </tr>
         <tr><td>Parameter</td>
            <td>Numeric measure describing a characteristic of the
               <i>population</i>.
            </td>
         </tr>
         <tr><td>Statistic</td>
            <td>Numeric measure describing a characteristic of the <i>sample</i>.
               Statistics are used to <em>infer</em> population parameters.
            </td>
         </tr>
         <tr><td>Inference</td>
            <td>The process of making conclusions about the propulation from noisy
               data that was drawn from it. Involves formulating conclusions using data
               and quantifying the uncertainty associated with those conclusions.
            </td>
         </tr>
      </tbody>
   </table>

   <h4>Experiments...</h4>
   <table class="dataDefTable noborder">
      <tbody>
         <tr><td>Random Experiment</td>
            <td>Action(s) that can lead to $\ge$2 outcomes where one cannot be sure,
               before performing the experiment, what the outcome would be.
            </td>
         </tr>
         <tr><td>Basic Outcomes</td>
            <td>A possible outcome from a random experiment. For example, flipping
               a coin has two basic outcomes: heads or tails.
            </td>
         </tr>
         <tr><td>Sample Space</td>
            <td>The set of all possible basic outcomes (exhaustively) from a random experiment.
               Note that this implies that the total number of possible outcomes is, or can be, known.
            </td>
         </tr>
         <tr><td>Event</td>
            <td>A subset of basic outcomes from a sample space. For example,
               a dice roll has 6 basic outcomes, 1 through 6. The sample space
               is therefore the set <code>{1, 2, 3, 4, 5, 6}</code>. The event
               &quot;roll a 2 or 3&quot; is the set <code>{2, 3}</code>.
            </td>
         </tr>
      </tbody>
   </table>

   <h4>Distributions...</h4>
   <table class="dataDefTable noborder">
      <tbody>
         <tr><td>Probability Mass Function (PMF)</td>
            <td>When evaluation a <i>n</i> function gives the probability that
               a random variable takes the value <i>n</i>. Only associated
               with <em>discrete</em> random variables. Also note that the
               function <b>descibes the population</b>.
            </td>
         </tr>
         <tr><td>Probability Density Function (PDF)</td>
            <td>Only associated with <em>continuous</em> random variables.
               The area between two limits corresponds to the probabilty that the random
               variable lies within those limits. A single point has
               a zero probability. Also note that the
               function <b>descibes the population</b>.
            </td>
         </tr>
         <tr><td>Cumulative Distribution Function (CDF)</td>
            <td>Returns the probability that $X \le x$.
            </td>
         </tr>
         <tr><td>Quantile</td>
            <td>The $\alpha^{th}$ quantile of a distribution, $F$, is the point
               $x_\alpha$ such that $F(x_\alpha) = \alpha$.
            </td>
         </tr>
      </tbody>
   </table>

   <p></p>

   <h3>Population And Sample <i>Space</i></h3>
   <p>
      We have said that the population is the complete set of items of interest.
   </p>
   <p>
      We have said that the sample space is the set of all possible outcomes (exhaustively) from a random experiment.
   </p>
   <p>
      So I wondered this. Take a dice roll. The population is the complete set of possible items <code>{1, 2, 3, 4, 5, 6}</code>.
      The sample space is the set of all possible outcomes, also <code>{1, 2, 3, 4, 5, 6}</code>. So here sample space and
      population appear to be the same thing, so when are they not and what are the distinguishing factors between the two??
   </p>
   <p>
      The <a href="https://en.wikipedia.org/wiki/Sample_space" target="_blank">WikiPedia page on sample spaces</a> caused the penny to drop for me:
   </p>
   <p>
      <q>...For many experiments, there may be more than one plausible sample space available, depending on what result is of interest to the experimenter. For example, when drawing a card from a standard deck of fifty-two playing cards, one possibility for the sample space could be the various ranks (Ace through King), while another could be the suits (clubs, diamonds, hearts, or spades)...</q>
   </p>
   <p>
      Ah ha! So my population is the set of all cards <code>{1_heart, 2_heart, ...,
      ace_heart, 1_club, ...}</code> but the sample space may be, if we are looking
      for the suits, just <code>{heart, club, diamond, spade}</code>. So the population and
      sample space are different here. In this case the sample space consists of cards
      separated into groups of suites. I.e. the popultation has been split into 4
      groups because there are 4 events of interest. These events cover the sample space.
   </p>
   <p>
      In summary the population is the set of items I'm looking at. The sample space may or may not be
      the population... that depends on what question about the population is being asked and how
      the items in the population are grouped per event.
   </p>

   <h3><a name="classicprob">Classic Probability</a></h3>
   <p>
   In classic probability we assume <em>all the basic outcomes are equally likely</em>
      and therefore the probability of an event, A, is the number of basic
      outcomes associated with A divided by the total number of possible outcomes:

      $$
      \begin{align}
      P(A) &amp;= \frac{\text{number of outcomes relevant to event A}}{\text{total number of outcomes}} \\
      &amp;= \frac{N_A}{N}
      \end{align}
      $$

      Each basic output is <em>equally likely</em>. And, note, here we are talking
      about outcomes in the <em>population</em>.
   </p>
   <p>
      An example of the use of classical probability might be a simple bag of
      marbles. There are 3 blue marbles, 2 red, and 1 yellow.
   </p>
   <p>
      If my experiment is to draw out 1 marble then the set of basic outcomes
      is
      <code>{B<sub>1</sub>, B<sub>2</sub>, B<sub>3</sub>,
           R<sub>1</sub>, R<sub>2</sub>, Y<sub>1</sub>}</code>.
      This is also the population!
      Also, note that the sample space isn't
      <code>{B, R, Y}</code> because we can differentiate between similar coloured
      marbles and there is a certain quanity of each.
   </p>
   <p>
      So, what is the probability of picking out a red. Well, here $N = 6$ and
      $N_A = 2$ because there are 2 red marbles in the sack. Therefore the
      probability is:

      $$
         P(red) = \frac{2}{6} = \frac{1}{3}
      $$
   </p>
   <a name="stats_eg_of_perms_and_combs"></a>
   <p>
      What if my experiment is to draw 2 marbles from the sack? Now the set
      of all possible basic outcomes, if the order of draw was important
      would be a
      <a href="math_revision.html#combinations_permutations">permutation</a>.
      This means that if I draw, for example, R<sub>1</sub> then B<sub>2</sub>,
      I would consider it to be a distinctly different outcomes to drawing
      B<sub>2</sub> then R<sub>1</sub>. That means my population is:
   </p>
   <table class="allborders">
      <tbody>
        <tr><td>Selection 1</td>    <td>Selection 2</td>        <td>Selection 1</td>    <td>Selection 2</td></tr>
        <tr><td>B<sub>1</sub></td>  <td>B<sub>2</sub></td>      <td>B<sub>2</sub></td>  <td>B<sub>1</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>B<sub>3</sub></td>      <td>B<sub>2</sub></td>  <td>B<sub>3</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>R<sub>1</sub></td>      <td>B<sub>2</sub></td>  <td>R<sub>1</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>R<sub>2</sub></td>      <td>B<sub>2</sub></td>  <td>R<sub>2</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>Y<sub>1</sub></td>      <td>B<sub>2</sub></td>  <td>Y<sub>1</sub></td></tr>


        <tr><td>B<sub>3</sub></td>  <td>B<sub>1</sub></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>B<sub>2</sub></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>R<sub>1</sub></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>R<sub>2</sub></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>Y<sub>1</sub></td>      <td></td><td></td></tr>

        <tr><td>R<sub>1</sub></td>  <td>R<sub>2</sub></td>      <td>R<sub>2</sub></td>  <td>R<sub>1</sub></td></tr>
        <tr><td>R<sub>1</sub></td>  <td>B<sub>1</sub></td>      <td>R<sub>2</sub></td>  <td>B<sub>1</sub></td></tr>
        <tr><td>R<sub>1</sub></td>  <td>B<sub>2</sub></td>      <td>R<sub>2</sub></td>  <td>B<sub>2</sub></td></tr>
        <tr><td>R<sub>1</sub></td>  <td>B<sub>3</sub></td>      <td>R<sub>2</sub></td>  <td>B<sub>3</sub></td></tr>
        <tr><td>R<sub>1</sub></td>  <td>Y<sub>1</sub></td>      <td>R<sub>2</sub></td>  <td>Y<sub>1</sub></td></tr>

        <tr><td>Y<sub>1</sub></td>  <td>B<sub>1</sub></td>      <td></td><td></td></tr>
        <tr><td>Y<sub>1</sub></td>  <td>B<sub>2</sub></td>      <td></td><td></td></tr>
        <tr><td>Y<sub>1</sub></td>  <td>B<sub>3</sub></td>      <td></td><td></td></tr>
        <tr><td>Y<sub>1</sub></td>  <td>R<sub>1</sub></td>      <td></td><td></td></tr>
        <tr><td>Y<sub>1</sub></td>  <td>R<sub>2</sub></td>      <td></td><td></td></tr>
      </tbody>
   </table>
   <p>
      Which is a real nightmare to compute by trying to figure out all the permutations by
      hand, and imagine, this is only a small set! Maths to the rescue...
   </p>
   <p>
      $$
         \begin{align}
            Permutations &amp;= {_{n}P_r} = \frac{n!}{(n-r)!} \\
                         &amp;= {_{6}P_2} = \frac{6!}{(6-2)!} \\
                         &amp;= \frac{6 \times 5 \times 4 \times 3 \times 2 }{4 \times 3 \times 2} \\
                         &amp;= 6 \times 5 \\
                         &amp;= 30
         \end{align}
      $$
   </p>
   <p>
      And that is how many permutations we have in the above table (thankfully!).
   </p>
   <p>
   So, if my question is what is the probability of drawing a red <em>then</em> a yellow
      marble, my event space is the set
      <code>{R<sub>1</sub>Y<sub>1</sub>, R<sub>2</sub>Y<sub>1</sub>}</code>.<br>
      Thus, if we say event A is &quot;draw a red then a yellow marble&quot;,

      $$
         P(A) =  \frac{N_A}{N} = \frac{2}{30} = \frac{1}{15}
      $$
   </p>

   <p>
      What if we don't care about the order. What is the probability of
      drawing a red <em>and</em> a yellow? I.e. we consider RY and YR to be
      the same event...
   </p>
   <p>
      Our event space therefore becomes:
      <br>
      <code>{R<sub>1</sub>Y<sub>1</sub>, R<sub>2</sub>Y<sub>1</sub>
           Y<sub>1</sub>R<sub>1</sub>, Y<sub>1</sub>R<sub>2</sub>}</code>.
   </p>
   <p>
      Thus, if we say event A is &quot;draw a red and a yellow marble&quot;,

      $$
         P(A) =  \frac{N_A}{N} = \frac{4}{30} = \frac{2}{15}
      $$
   </p>

   <p>
      We are essentially now
      dealing with <a href="math_revision.html#combinations_permutations">combinations</a>.
   </p>
   <p>
      Therefore in the above table, where we see things like...
   </p>
   <table class="allborders">
      <tbody>
         <tr><td>Selection 1</td>    <td>Selection 2</td></tr>
         <tr><td>B<sub>1</sub></td>  <td>B<sub>2</sub></td></tr>
         <tr><td>B<sub>2</sub></td>  <td>B<sub>1</sub></td></tr>
      </tbody>
   </table>
   <p>
      ...we can delete one of the rows. The set of all basic outcomes therefore
      becomes:
   </p>
   <table class="allborders">
      <tbody>
        <tr><td>Selection 1</td>    <td>Selection 2</td>        <td>Selection 1</td>    <td>Selection 2</td></tr>
        <tr><td>B<sub>1</sub></td>  <td>B<sub>2</sub></td>      <td><del>B<sub>2</sub></del></td>  <td><del>B<sub>1</sub></del></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>B<sub>3</sub></td>      <td>B<sub>2</sub></td>  <td>B<sub>3</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>R<sub>1</sub></td>      <td>B<sub>2</sub></td>  <td>R<sub>1</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>R<sub>2</sub></td>      <td>B<sub>2</sub></td>  <td>R<sub>2</sub></td></tr>
        <tr><td>B<sub>1</sub></td>  <td>Y<sub>1</sub></td>      <td>B<sub>2</sub></td>  <td>Y<sub>1</sub></td></tr>


        <tr><td><del>B<sub>3</sub></del></td>  <td><del>B<sub>1</sub></del></td>      <td></td><td></td></tr>
        <tr><td><del>B<sub>3</sub></del></td>  <td><del>B<sub>2</sub></del></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>R<sub>1</sub></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>R<sub>2</sub></td>      <td></td><td></td></tr>
        <tr><td>B<sub>3</sub></td>  <td>Y<sub>1</sub></td>      <td></td><td></td></tr>

        <tr><td>R<sub>1</sub></td>  <td>R<sub>2</sub></td>      <td><del>R<sub>2</sub></del></td>  <td><del>R<sub>1</sub></del></td></tr>
        <tr><td><del>R<sub>1</sub></del></td>  <td><del>B<sub>1</sub></del></td>      <td><del>R<sub>2</sub></del></td>  <td><del>B<sub>1</sub></del></td></tr>
        <tr><td><del>R<sub>1</sub></del></td>  <td><del>B<sub>2</sub></del></td>      <td><del>R<sub>2</sub></del></td>  <td><del>B<sub>2</sub></del></td></tr>
        <tr><td><del>R<sub>1</sub></del></td>  <td><del>B<sub>3</sub></del></td>      <td><del>R<sub>2</sub></del></td>  <td><del>B<sub>3</sub></del></td></tr>
        <tr><td>R<sub>1</sub></td>  <td>Y<sub>1</sub></td>      <td>R<sub>2</sub></td>  <td>Y<sub>1</sub></td></tr>

        <tr><td><del>Y<sub>1</sub></del></td>  <td><del>B<sub>1</sub></del></td>      <td></td><td></td></tr>
        <tr><td><del>Y<sub>1</sub></del></td>  <td><del>B<sub>2</sub></del></td>      <td></td><td></td></tr>
        <tr><td><del>Y<sub>1</sub></del></td>  <td><del>B<sub>3</sub></del></td>      <td></td><td></td></tr>
        <tr><td><del>Y<sub>1</sub></del></td>  <td><del>R<sub>1</sub></del></td>      <td></td><td></td></tr>
        <tr><td><del>Y<sub>1</sub></del></td>  <td><del>R<sub>2</sub></del></td>      <td></td><td></td></tr>
      </tbody>
   </table>
   <p>Again a nightmare to figure out by hand, so maths to the resuce...
   </p>
    <p>
      $$
         \begin{align}
            Combinations &amp;= {_{n}P_r} = \frac{n!}{r!(n-r)!} \\
                         &amp;= {_{6}P_2} = \frac{6!}{2!(6-2)!} \\
                         &amp;= \frac{6 \times 5 \times 4 \times 3 \times 2 }{4 \times 3 \times 2 \times 2} \\
                         &amp;= \frac{6 \times 5}{2} \\
                         &amp;= 15
         \end{align}
      $$
   </p>
   <p>
      And, again, that is how many selections (not included the ones we've deleted using a strikethrough font)
      we have in the above table (thankfully!).
   </p>
   <p>
      So, now we can't ask about drawing a red <em>then</em> a yellow
      marble anymore as order doesn't matter. We can ask about drawing a red
      <em>and</em> a yellow though.
      My event space is now the set <br>
      <code>{R<sub>1</sub>Y<sub>1</sub>, R<sub>2</sub>Y<sub>1</sub>
         <del>Y<sub>1</sub>R<sub>1</sub>, Y<sub>1</sub>R<sub>2</sub></del>}</code><br>
      because I not longer care about order-of-draw...

      Thus, if we say event A is &quot;draw a red and a yellow marble&quot;,
      $$
         P(A) =  \frac{N_A}{N} = \frac{2}{15}
      $$
   </p>
   <p>
   		We have noted that in classical probability that the various outcomes <em>are equally likely</em>.
   		This means that from my bag of marbles am am equally likely to pick any marble. But what if this
   		was not the case? What if the blue marbles are very heavy and sink to the bottom of the sack whilst
   		the other marbles tend to rest on top of the blue marbles. We could hardly say that I am as likely
   		to pick a blue as I am a red in this case. In this cas we <em>cannot</em> use classical probability
   		to analyse the situation.
   </p>

   <h3>Relative Frequency Probability</h3>
   <p>
      Here the probability of an
      event occurring is is the limit of the proportion of times an event occurs in
      a large number of trials. Why the limit? Well, the limit would mean we tested
      the entire population. Usually, however, we just pick a very large <i>n</i>
      and <em>infer</em> the population statistic from that.
      $$
      P(event) = \lim \limits_{n \to \infty} \frac{n_A}{n}
      $$

      Where $n_a$ is the number of experimental outcomes relevant to event A,
      and $n$ is the total number of outcomes.
   </p>

   <p>
      So, for example, if we flip a coin 1000 times there are 1000 total number of outcomes.
      If we observed 490 heads and 510 tails we would have...
      $$\begin{align}
      P(head) &amp;= \frac{490}{1000} &amp;= 0.49  \\

      P(tail) &amp;= \frac{510}{1000} &amp;= 0.51
      \end{align}$$
   </p>
   <p>
      If the coin was entirely fair then we would expect an equal probability
      of getting a head or a tail. Frequentist theory states that as the sample
      size gets bigger, i.e., as we do more and more coin flips, if the coin
      is fair the probabilities will tend towards 50%. So if we did 1,000,000
      samples, for example, we might expect...

      $$\begin{align}
      P(head) &amp;= \frac{500100}{1000000} &amp;= 0.5001  \\

      P(tail) &amp;= \frac{499900}{1000000} &amp;= 0.4999
      \end{align}$$

      So... more samples, the closer our probability estimate is to the <em>real</em>
      probabilities for getting a head or tail. The limit of the probabilities as
      the sample size tends to infinitely will be exactly 50%. The &quot;<em>real</em>&quot;
      is the probability from the <em>population</em>. Anything less is a <em>sample</em>
      of the population.
   </p>

   <p>
      As <i>n</i> tends to infinity, we can say that <i>n</i> tends towards
      the population size, and then at this point you will arrive back at
      the formula for conditional probability you saw in the previous section
   </p>


   <h3>Event A <u>OR</u> Event B</h3>
   <table style="border:0px">
      <tbody>
         <tr><td>$A$ and $B$ are <em>independent</em>:</td><td>$P(A \cup B) = P(A) + P(B)$</td></tr>
         <tr><td>$A$ and $B$ are <em>not</em> independent:</td><td>$P(A \cup B) = P(A) + P(B) - P(A \cup B)$</td></tr>
      </tbody>
   </table>
   <p>
     What is independence? A and B are said to be independent if information on the value of A does not give any information on the value of B, and vice versa.
   </p>
   <p>
      We can visualise this as follows, using a Venn diagram...
   </p>
   <p>
      <a name="two_independent_venn">
         <img src="##IMG_DIR##/Prob_A_and_B_independent.png" alt="Venn diagram of probability for A and B and A or B when events are independent">
      </a>
   </p>
   <p>
      If two events are independent then we can see that none of the basic outcomes from either event can occur for the other.
      Therefore, using either classical or relative-frequency probability we can see that $P(A \cup B) = P(A) + P(B)$.
   </p>
   <p>
      <a name="two_dependent_venn">
         <img src="##IMG_DIR##/Prob_A_and_B_dependent.png" alt="Venn diagram of probability for A and B and A or B when events are dependent">
      </a>
   </p>
   <p>
      Now the two events are related. They are no longer independent because some of the basic
      outcomes from one event are also basic outcomes of the other. Thus we can see that
      if we sum the probabilities for the basic outcomes for each, we will count the shared
      basic outcomes twice!
   </p>
   <p>
      If that's not clear, think of it this way...
   </p>
   <p>
      <img src="##IMG_DIR##/Prob_A_and_B_double_count.png" alt="">
   </p>

   <h3>Event A <u>AND</u> Event B</h3>
   <p>
      We just talked about independence, but how do we know if an event A, is
      independent of another event, B? The answer is that <b>two events are
      indpendent if $P(A \cap B) = P(A)P(B)$</b>.
   </p>
   <p>
      Why is this? Let's think of this from the relative frequency point of
      view. We know that $P(A) = n_a/n$ and that $P(B) = n_b/n$ for the sample
      and as n tends to infinity for the population.
    </p>
    <p>
      For every basic outcome in the set A, we can
      pick an outcome from the set B, so the count of the combination of all possible
      outcomes from both sets must be $n_a \times n_b$. But this only makes
      sense if the events are mutually exlusive (i.e., don't overlap).

      $$
         P(A)P(B) = \frac{n_a \times n_b}{n}
      $$

      (See the previous <a href="#two_independent_venn">figure of a Venn Diagram for two independent events</a>
      to make this more clear in your mind).
   </p>
   <p>
      So, what if the events are <em>not</em> independent? Then it is no longer true
      that the count of combination of all possible outcomes is $n_a \times n_b$.
      Why is this? This is because the events that can be in both A and B
      now represent a much smaller portion of sample space. The probability
      that A and B occur is now the solid-gray shaded area of the
      <a href="#two_dependent_venn">Venn diagram for dependent events</a>.
   </p>
   <p>
      Think if it this way. For A and B to both occur, at least one must have
      occurred, so now the only possible choices from the other event are
      in the overlapping region, not in the entire event space. Keep reading
      the next section on condition probability to find out more
      about why this is an indicator of independence.
   </p>
   <table class="allborders">
      <tbody>
         <tr><td></td>              <td>$A$</td>                  <td>$\overline A$</td>                  <td></td></tr>
         <tr><td>$B$</td>           <td>$A \cap B$</td>           <td>$\overline A \cap B$</td>           <td>$\Sigma = P(B)$</td></tr>
         <tr><td>$\overline B$</td> <td>$A \cap \overline B$</td> <td>$\overline A \cap \overline B$</td> <td>$\Sigma = P(\overline B)$</td></tr>
         <tr><td></td>              <td>$\Sigma = P(A)$</td>      <td>$\Sigma = P(\overline A)$</td>      <td>$\Sigma = 1$</td></tr>
      </tbody>
   </table>

   <a name="conditional_prob"><h3>Event A <u>GIVEN</u> Event B</h3></a>
   <p>
      If I live with my partner it seems intuitively correct to say that the
      probability of myself getting a cold would be heightened if my partner
      caught a cold. Thus there is an intuitive difference between the
      probability I will catch a cold and the probability that I will catch
      a cold, given my partner has already caught one.
   </p>
   <p>
      This is the idea behind <em>conditioning</em>: conditioning on what
      you know can change the probability of an outcome with no apriori
      knowledge of the data.
   </p>
   <p>
      <img src="##IMG_DIR##/Prob_Conditional.png" alt="Conditional probability venn diagram">
   </p>
   <p>
      Lets look at a really simple example. I roll a dice... what is the probability
      that I roll a 3. We assume a fair dice, so the answer is easy: 1/6.
      The set all of basic outcomes was <code>{1, 2, 3, 4, 5, 6}</code> (the sample space) and only
      one outcome was relevant for our event... so 1/6.
   </p>
   <p>
      Now lets say I have rolled the dice and I have been informed that the
      result was an odd number. With this knowledge, what is the probability that
      I rolled a 3? The set of basic outcomes is now narrowed to <code>{1, 3, 5}</code>
      and so the probability is now 1/3!
   </p>
   <p>
      The probability of event A given that event B has occurred is denoted
      $P(A | B)$ and is defined as follows:

      $$
      P(A | B) = \frac{P(A \cap B)}{P(B)}, \text{when}\ P(B) \ne 0
      $$
   </p>
   <p>
      This makes intuitive sense. If B has occurred then the number of outcomes
      to &quot;choose&quot; from is represented by the circle for B in the
      Venn diagram below. The number of of outcomes that can belong to event
      A, given that we know event B has occurred, is the intersection.
      Therefore, our sample space is really now all the outcomes for event B,
      so $n \equiv n_b$, and the event of interest for A is now restricted to
      $n_{a \cap b}$. So we get...

      $$
      P(A | B) = \frac{n_{a \cap b}}{n_b} = \frac{\frac{n_{a \cap b}}{n}}{\frac{n_b}{n}} = \frac{P(A \cap B)}{P(B)}
      $$
   </p>
   <p>
      If A and B are independent then clearly, because $n_{a \cap b} = 0$, $P(A | B) = 0$.
   </p>
   <p>
      We can re-arrange the above to get another formula for $P(A \cap B)$...

      $$
         P(A \cap B) = P(A | B)P(B)
      $$
   </p>
   <p>
      And now we can see why, if two events are independent that $P(A \cap B) = P(A)P(B)$...
      because when A and B are independent $P(A | B) \equiv P(A)$!. And when they are
      dependent that equality is not true.
   </p>
   <p>
      A small bit on terminology... $P(A)$ is ofter called the <b>prior</b> probability and
      $P(A | B)$ the <b>posterior</b> probability.
   </p>
   <p>
      <q>...A posterior probability is the probability of assigning observations
         to groups given the data. A prior probability is the probability that
         an observation will fall into a group before you collect the data. For
         example, if you are classifying the buyers of a specific car, you might
         already know that 60% of purchasers are male and 40% are female. If you
         know or can estimate these probabilities, a discriminant analysis can
         use these prior probabilities in calculating the posterior probabilities.
      </q><br>
      <i>-- <a href="http://support.minitab.com/en-us/minitab/17/topic-library/modeling-statistics/multivariate/discriminant-analysis/what-are-posterior-and-prior-probabilities/" target="_blank">Minitab support</a></i>
   </p>
   <p>
      From the definitions so far we can also see that

      $$
         P(A | B) + P(\overline A | B) = 1
      $$

      But that the following does not (necessarily) equal 1,

      $$
         P(A | B) + P(A | \overline B) \ne 1
      $$
   </p>

   <p>
      Why is this important? Let's look at a little example. Say we have a
      clinical test for Influenza. Imagine that we know that for a patient the
      probability that they have or do not have Influenza.

      $$
      P(Flu) = 0.05 \implies P(\overline{Flu}) = 0.95
      $$
   </p>
   <p>
      Any clinical test is normally judged by it's sensitivity and specificity.
      Sensitivity is the probability that the test reports infection if the
      patient has Influenza (i.e true positives).
      Sepcificity is the probability that the test
      reports the all-clear if the patient does not have Influenza (i.e., true
      negatives).
   </p>
   <p>
      Let's say the test has the following sensitivity and specificity respectively:

      $$
      \begin{align}
      P(+ | Flu) &amp;= 0.9  \\
      P(- | \overline{Flu}) &amp;= 0.9
      \end{align}
      $$

      Because we know $ P(A | B) + P(\overline A | B) = 1$, we can say:

      $$
      \begin{align}
      P(- | Flu) &amp;= 0.1 \\
      P(+ | \overline{Flu}) &amp;= 0.1
      \end{align}
      $$

      But a clinitian wants to know the probabilities the other way around. The
      clinician will ask &quot;if my patient has the flu, what is the probability
      that the test will call a positive?&quot; I.e., the clinician wants to
      know $P(Flu | +)$
   </p>
   <p>
      We can use the conditional probability formula to work this out...

      $$
      \begin{align}
         P(Flu | +) &amp;= \frac{P(Flu \cap +)}{P(+)} \\
         &amp;= \frac{P(+ \cap Flu)}{P(+)}
      \end{align}
      $$

      We can find out $P(+ \cap Flu)$ because $P(+ \cap Flu) = P(+ | Flu)P(Flu)$,
      which are quantities we already know, so we get...

      $$
      \begin {align}
         P(+ \cap Flu) &amp;= P(+ | Flu)P(Flu) \\
                       &amp;= 0.9 \times 0.05 \\
                       &amp;= 0.045
      \end{align}
      $$

      We're close, but what is the value for $P(+)$? The answer is
      $P(+) = P(+ \cap Flu) + P(+ \cap \overline{Flu})$:

      $$
      \begin{align}
      P(+) &amp;= P(+ \cap Flu) + P(+ \cap \overline{Flu}) \\
           &amp;= 0.045 + ?
      \end{align}
      $$

      We still need to know $P(+ \cap \overline{Flu})$. We know that
      $P(+ \cap \overline{Flu}) = P(+ | \overline{Flu})P(\overline{Flu})$, and we know
      these quantities already, so:

      $$  P(+ \cap \overline{Flu}) = 0.1 * 0.95 = 0.095
      $$

      Therefore,

      $$P(+) = 0.045 + 0.095 = 0.14$$

      Which means we can work out the entire thing (to 4dp):

      $$ P(Flu|+) = \frac{0.045}{0.14} = 0.3214
      $$
   </p>




   <h3>Sensitivity v.s. Specificity</h3>
   <p>
      In clinical tests, the user often wants to know about the sensitivity of a
      test. I.e., if the patient does have the disease being tested for, what
      is the probability that that the test will call a positive results. Obviously,
      we would like this to be as close to 100% as possible!
   </p>
   <p>
      The clinician would also like to know, if the patient did not have the
      disease, what is the probability that the test calls a negative. Again,
      we would like this to be as close to 100% as possible!
   </p>
   <p>
      To summarise: sensitivity is the probability of a true positive, and
      specificity is the probability of a true negative.
   </p>
   <p>
      Sensitivity: $P(+ | D)$ <br>
      Specificity: $P(- | \overline D)$
   </p>

   <h3>Compliments</h3>
   <p>
      $$
         P(A \cup \overline A) = P(A) + P(\overline A) = 1\\
         P(\overline A) = 1 - P(A)
      $$
   </p>

   <h3>Bayes' Theorem</h3>
   <p>
      Recall the multiplication rule:

      $$
         P(A \cap B) = P(A | B)P(A) = P(B | A)P(A)
      $$

      By re-arranging the above we can arrive at the following:

      $$
         P(A | B) = \frac{P(B | A)P(A)}{P(B)},\ \ \ P(B | A) = \frac{P(A | B)P(B)}{P(A)}
      $$
   </p>
   <p>
      Because we know that $P(B) = P(A \cap B) + P(\overline A \cap B)$ we
      could also write:

      $$
         P(A | B) = \frac{P(B | A)P(A)}{P(A \cap B) + P(\overline A \cap B)}
      $$

      An because we know $P(A \cap B) = P(B | A)P(A)$ and  $P(\overline A \cap B) = P(\overline B | A)P(A)$,
      we can re-write this as:

      $$
         P(A | B) = \frac{P(B | A)P(A)}{P(B | A)P(A) + P(\overline B | A)P(A)}
      $$
   </p>

   <p>
      Remember that we called $P(x)$ the <em>prior</em> probability. The prior is the
      probability distribution that represents your uncertainty over the random variable
      X. The <em>posterior</em> is the distribution representing your uncertainty after
      you have observed events that are related to or influence your event-of-interest: It is
      a conditional distribution, conditioning on the observed data. Bayes' theorem has
      given us a way to relate the two.
   </p>
   <p>
      <img src="##IMG_DIR##/bayes_rule_flow_chart.PNG"
           alt="Flow diagram of Bayes Rule converting prior probability to posterior">
   </p>



      <h4>Alternative Statement</h4>
      <p>
         This can sometimes be usefull re-stated as follows. If all events $E_i$ are
         mutually exclusive and exhaustive and we have some other event A then we can
         write:

         $$
            P(E_i | A) = \frac{P(A | E_i)P(E_i)}{P(A)}
         $$

         And because in this case,

         $$
         \begin{align}
            P(A) &amp;= P(A \cap E_1) + P(A \cap E_2) + \cdots + P(A \cap E_n) \\
                 &amp;= P(A | E_1)P(E_1) + P(A | E_2)P(E_2) + \cdots + P(A | E_n)P(E_n)
         \end{align}
         $$

         We can say:

         $$
            P(E_i | A) = \frac{P(A | E_i)P(E_i)}{P(A | E_1)P(E_1) + P(A | E_2)P(E_2) + \cdots + P(A | E_n)P(E_n)}
         $$

         The advantage of this expression is that the probabilities involves are sometimes
         more readily available.
      </p>

<h2>Discrete Probability Distributions</h2>
<div>
   <h3>General Definitions</h3>
   <p>
      The <b>Probability Mass Function (PMF)</b> is another name for the <b>Probability
      Distribution Function (PDF)</b>, $P(x)$, of a discrete random variable X
      expresses the probability that $X$ takes the value $x$. I.e,

      $$
      P(x) \equiv P(X = x), \ \  \forall x
      $$

      The PMF has the following properties:

      $$
      0 \le P(x) \le 1\, \  \forall x\\
      \sum_x P(x) = 1
      $$
   </p>
   <p>
      The <b>Cumulative Mass Function (CMF)</b> or <b>Cumulative Probability Function (CPF)</b>,
      $F(x_0)$, for a random variable $X$,
      gives the probability that X does not exceed the value $x_0$:

      $$ F(x_0) = P(X \le x_0) = \sum_{x \le x_0} P(x)$$

      The CMF has the following properties:

      $$
      0 \le F(X_0) \le 1, \ \ \forall x_0\\
      x_0 \lt x_1 \implies F(x_0) \lt F(x_1)
      $$
   </p>
   <h3>Expected Value and Variance</h3>
   <p>
      <a name="def_expected_value">
      <b>Expected value</b> defined as:

      $$
      E(X) = \mu = \sum_x xP(x)
      $$
      </a>

      Where $\mu$ is called the <b>mean</b> and is the mean of the <b>population</b>.
   </p>
   <p>
      The calculation of measurements like $E(X^2)$ becomes...

      $$
         E(X^2) = \sum_x x^2P(x)
      $$
   </p>
   <p>
      <b>Variance</b>, $\sigma^2$ is the average squared distance from the mean and is
      defined as follows. The square is taken so that distances don't cancel
      eachother out (i.e, a negative distance and positive distance could
      result is a very small average distance, which is not what we want).

      $$
      \begin{align}
         \text{Var}(X) = \sigma^2 &amp;= \sum_x (x - \mu)^2P(x) \\
         &amp;= E[(X - \mu)^2] \\
      \end{align}
      $$

      We can re-write this as follows:

      $$
      \begin{align}
         \text{Var}(X) = \sigma^2 &amp;= \sum_x (x - \mu)^2P(x) \\
         &amp;= \sum_x (x^2 - 2x\mu + \mu^2)P(x) \\
         &amp;= \sum_x x^2P(x) - 2\mu\sum xP(x) + \mu^2\sum P(x) \\
         &amp;= E[X^2] - 2\mu E[X] + E[X]^2 \\
         &amp;= E[X^2] - 2E[X]^2 + E[X]^2 \text{  , (because } \mu == E[X]\text{ and } \therefore \mu E[X] == E[X]^2 \text{)}\\
         &amp;= E[X^2] - E[X]^2
      \end{align}
      $$


      In summary,

      $$
       \text{Var}(X) = E[(X - \mu)^2] = E(X^2) - \mu^2 = E(X^2) - E(X)^2
      $$
   </p>
   <p>
      <b>Standard Deviation</b>, $\sigma$, is the positive square root of
      the variance.
   </p>
   <p>
      The calculation of measurements like $\text{Var}(aX)$ becomes...

      $$
      \begin{align}
         \text{Var}(aX) &amp;= E[(aX)^2] - E[aX]^2 \\
         &amp;= E[a^2X^2] - (aE[X])^2 \\
         &amp;= a^2E[X^2] - a^2E[X]^2 \\
         &amp;= a^2(E[X^2] - E[X]^2) \\
         &amp;= a^2\text{Var}(X)
      \end{align}\\
      $$

   </p>
   <p>
      Why does $E[(X - \mu)^2]$ equal $E(X^2) - \mu^2$?

      $$
      \begin{align}
          E[(X - \mu)^2] &amp;= \Sigma_i P()[x_i - \mu]^2\\
          &amp;= \Sigma_i P(x_i)[x_i^2 - 2x_i\mu +\mu^2]\\
          &amp;= \Sigma_i P(x_i)x_i^2 - 2\mu\Sigma_i P(x_i)x_i + \mu^2 \Sigma_i P(x_i)
      \end{align}
      $$

      From our definition of $E(X)$ we know that ...

      $$
          \Sigma_i P(x_i)x_i^2 = E(X^2)
      $$

      And...

      $$
      \begin{align}
         2\mu\Sigma_i P(x_i)x_i &amp;= 2\mu E(X)\\
         &amp;= 2E(X)E(X) \\
         &amp;= 2E(X)^2
      \end{align}
      $$

      We also know that the sum of all the probabilities in the distribution
      must sum to 1, so therefore...

      $$
      \mu^2 \Sigma_i P(x_i) = \mu^2
      $$

      Thus we can say this...

      $$
      \begin{align}
          E[(X - \mu)^2] &amp;= E(X^2) - 2E(X)^2 + E(X)^2 \\
          &amp;= E(X^2) - E(X)^2
      \end{align}
      $$

      Yay!
   </p>
   <p>
      For example, lets say that we have weighted dice so that the
      probabilities are as follows:
   </p>
   <table class="allborders">
      <tbody>
         <tr><td>Value</td><td>Probability</td></tr>
         <tr><td>1</td><td>0.05</td></tr>
         <tr><td>2</td><td>0.1</td></tr>
         <tr><td>3</td><td>0.1</td></tr>
         <tr><td>4</td><td>0.1</td></tr>
         <tr><td>5</td><td>0.1</td></tr>
         <tr><td>6</td><td>0.55</td></tr>
      </tbody>
   </table>
   <p>
      The population mean, $\mu$ becomes:
      $$
      E[X] = \mu = \sum_x xP(x) = 1\times 0.05 + 0.1 \times 2 + 0.1 \times 3 + 0.1 \times 4 + 0.1 \times 5 + 0.55 \times 6 = 4.75
      $$

      Of course, the dice does not have a face value of 4.75, but over many many rolls this would be the average score.
      The variance and standard deviation are calculated in the same way using the above formulas.
   </p>

   <h4><a name="linear_functions_of_x">Linear Functions Of X</a></h4>

   <p>
      The expected value and variance of a linear function of $X$ is another fairly useful result and
      we will use it to get some very important results in <a href="#SamplingDistributions">the section
      on sampling distributions</a>.
      For example, we could arbitrarily define a function over dice rolls. Not sure why we'd do this,
      but say we said the experiement result was $g(X) = 2X + 5$ where $X$ is the random variable which gives
      the dice face rolled. Now we have:
   </p>
   <table class="allborders">
      <tbody>
         <tr><td>g(x)</td><td>Probability</td></tr>
         <tr><td>7</td><td>0.05</td></tr>
         <tr><td>9</td><td>0.1</td></tr>
         <tr><td>11</td><td>0.1</td></tr>
         <tr><td>13</td><td>0.1</td></tr>
         <tr><td>15</td><td>0.1</td></tr>
         <tr><td>17</td><td>0.55</td></tr>
      </tbody>
   </table>
   <p>
      The expected value of $g(x)$ is therefore:
      $$
      E[g(X)] = \mu = \sum_x xP(x) = 7 \times 0.05 + 0.1 \times 9 + 0.1 \times 11 + 0.1 \times 13 + 0.1 \times 15 + 0.55 \times 17 = 14.5
      $$

      Interestingly $14.5 = 2 \times 4.75 + 5$! It looks like $E[g(X)] = g(\mu_x)$, and
      for <em>linear</em> functions this is the case (but not so if $g(X)$ is not linear!).
      When $g(X)$ is <b>LINEAR</b> and $g(X) = a + bX$:

      $$
      \begin{align}
      \mu_{g(X)} &amp;= E[a + bX] \\
                 &amp;= a + b\mu_X \\
                 \\
      \sigma_{g(X)}^2 &amp;= var[a + bX] \\
                      &amp;= b^2\sigma_X^2
      \end{align}
      $$
   </p>
   <p>
      We can derive the first equation as follows, using our first definition
      of the expected value of a random variable.

      $$
      \begin{align}
      E[a + bX] &amp;= \sum (a + bx_i)P(x_i) \\
      &amp;= \sum aP(x_i) + \sum bx_iP(x_i) \\
      &amp;= a + b \sum x_iP(x_i) \\
      &amp;= a + bE[X] \\
      &amp;= a + b\mu_X
      \end{align}
      $$

      The same can be done for the variance can also be done in a similar manner.
      TODO: add this here.
   </p>

   <h3>Binomial Distribution</h3>
   <h4>Bernoulli Model</h4>
   <p>
      Experiment with two mutually exclusive and exhaustive outcomes. One has
      the probability $p$ and the other has probability $(1-p)$.

      $$
         \begin{align}
         P(0) &amp;= P(fail)\\
              &amp;= (1-p) \\
              \\
         P(1) &amp;= P(success) \\
              &amp;= p
         \end{align}
      $$

      Therefore, using the formulas for mean and variance from the previous
      sections, we can say the following.

      $$
      \begin{align}
         \mu_x &amp;= E[X] \\
         &amp;= \sum_x xP(x) \\
         &amp;= (0)(1-p) + (1)p \\
         &amp;= p\\
         \\
         \sigma_x^2 &amp;= E[(X-\mu)^2] \\
         &amp;= \sum(x - \mu_x)^2P(x) \\
         &amp;= p(1-p)
      \end{align}
      $$
   </p>
   <h4>Binomial Distribution</h4>
   <p>
      Bernoulli experiment repeated $n$ times where the repetitions are
      <b>independent</b>. This is like selection <b>with replacement</b>.
   </p>

   <p>
      We know from previous discussions that if two events are independent
      then $P(A \cap B) = P(A)P(B)$ and by extension that $P(A \cap B \cap \dots \cap Z) = P(A)P(B) \dots P(Z)$.
      Therefore if I do $n$ experiments and want to know the probablity of $m$
      successes <em>in a row</em> and then $n-m$ failures <em>in a row</em>, the probability is:

      $$
      \begin{align}
         P(m\ successes) &amp;= P(1)P(1)\dots P(1)P(0)P(0)\dots P(0) \\
         &amp;= p^m(1-p)^{n-m}
      \end{align}
      $$

      Where there are $m$ $P(1)$'s in the above equation and $(n-m)$ $P(0)$'s. BUT
      this would be the probability of getting $m$ successes <em>in a row</em> and then
      $(n-m)$ failures in a row. The question, however, doesn't care about the specific order:
      we dont care if we get SSFF.. or SFSF... or SSFS... and so on. We need to figure
      out how many of these combinations there are and account for this!
   </p>
   <p>
      Let's take a simple example. I have a bag with 5 balls in it: 3 blue, 2 red.
      What is the probability of drawing 1 blue ball and 1 red ball if I select
      using replacement (to make the selections independent). Replacement means
      that what ever ball I pick first, I record the result and then put it
      back in the bag before making my next pick. In this way, the probability
      of selecting a particular colour <em>does NOT change</em> per pick.
   </p>
   <p>
      Note that there are only 2 colours of ball in our bag... this is because
      we are talking about an experiement where there are only two outcomes,
      labeled &quot;success&quot; and &quot;failure&quot;. We could view
      selecting a blue as &quot;success&quot; and a red as &quot;failure&quot;,
      or vice versa.
   </p>
   <p>
   So... selecting a blue and a red ball. Sounds like $P(\text{blue}\ \cap\ \text{red})$ right?
      Well, almost, but <em>not quite</em>. Take a look at the sample space below,
      out of which, the events of interested are highlighted in a light blue colour.
   </p>
   <p>
      Here I am using an alphabetical subscript to indicate the specific ball. I.e.
      $B_x$ is a different ball to $B_y$. The order of selection is given by the
      order of writing. I.e., &quot;$B_x\ B_y$&quot; means $B_x$ was picked on the first turn and then
      $B_y$ was picked on the second turn.
   </p>
   <table class="allborders">
      <tbody>
         <tr><td>...</td>
            <td>$B_x$</td>
            <td>$B_y$</td>
            <td>$B_z$</td>
            <td>$R_x$</td>
            <td>$R_y$</td></tr>
         <tr><td>$B_x$</td>
            <td>$B_x B_x$</td>
            <td>$B_x B_y$</td>
            <td>$B_x B_z$</td>
            <td class="selcell">$B_x R_x$</td>
            <td class="selcell">$B_x R_y$</td></tr>
         <tr><td>$B_y$</td>
            <td>$B_y B_x$</td>
            <td>$B_y B_y$</td>
            <td>$B_y B_z$</td>
            <td class="selcell">$B_y R_x$</td>
            <td class="selcell">$B_y R_y$</td></tr>
         <tr><td>$B_z$</td>
            <td>$B_z B_x$</td>
            <td>$B_z B_y$</td>
            <td>$B_z B_z$</td>
            <td class="selcell">$B_z R_x$</td>
            <td class="selcell">$B_z R_y$</td></tr>
         <tr><td>$R_x$</td>
            <td class="selcell">$R_x B_x$</td>
            <td class="selcell">$R_x B_y$</td>
            <td class="selcell">$R_x B_z$</td>
            <td>$R_x R_x$</td>
            <td>$R_x R_y$</td></tr>
         <tr><td>$R_y$</td>
            <td class="selcell">$R_y B_x$</td>
            <td class="selcell">$R_y B_y$</td>
            <td class="selcell">$R_y B_z$</td>
            <td>$R_y R_x$</td>
            <td>$R_y R_y$</td>
         </tr>
      </tbody>
   </table>
   <p>
      There are two clear groups of outcomes that will satisfy the question.
      We see that in one group we drew a red ball first and in the other we
      drew a blue ball first. So, there are $5 \times 5$ total possible
      events, and of these $6 + 6$ are of interest. Therefore,

      $$
      \begin{align}
         P(\text{drawing a blue and a red}) &amp;= \frac{6}{25} + \frac{6}{25} \\
         &amp;= 2 \times \frac{6}{25}
      \end{align}
      $$

      But, hang on  minute! Isn't $P(\text{drawing a blue and a red})$ the same
      as $P(B \cap R)$?! Well, no, as we can see below...

      $$
         P(B \cap R) = P(B) \times P(R) = \frac{3}{5} \times \frac{2}{5} = \frac{6}{25}
      $$

      So the two expressions are clearly not the same thing. To clear up my
      confusion I asked the guys at Maths Exchange, and got the following
      <a href="http://math.stackexchange.com/questions/1705507/binomial-distribution-p-mboxblue-cap-mboxred-ne-p-mboxpick-a-blue-a"
         target="_blank">awesome answer</a> from a very nice chap named
      <a href="http://math.stackexchange.com/users/6622/joriki" target="_blank">Joriki</a>.
      Im quoting it (almost) verbatim because it was just so good!
   </p>
   <div style="border-left: 3px solid lightblue; padding-left: 10px;">
      <p>This confusion can be resolved by careful attention to definitions and notation.
      </p>
      <p>Where you write $P(B\cap R)$, you call the events $B$ and $R$
         &quot;a blue&quot; and &quot;a red&quot; respectively. Implicitly
         you're referring to two different draws (if you were referring to a
         single draw, you'd have $P(B\cap R)=0$), but you're not
         distinguishing the events accordingly, and this leads to confusion.
      </p>
      <p>
         The events you are interested are $B_1$, a blue ball is drawn on
         the first draw, $R_1$, a red ball is drawn on the first draw,
         $B_2$, a blue ball is drawn on the second draw, and $R_2$, a red
         ball is drawn on the second draw. We have $P(B_1)=P(B_2)=\frac35$
         and $P(R_1)=P(R_2)=\frac25$.
      </p>
      <p>You want to know $P((B_1\cap R_2)\cup(B_2\cap R_1))$. Since the
         events $B_1\cap R_2$ and $B_2\cap R_1$ are mutually exclusive, this is

         $$P((B_1\cap R_2)\cup(B_2\cap R_1))=P(B_1\cap R_2)+P(B_2\cap R_1)\;,$$

         and since the first and second draws are independent, this is

         $$
         \begin{align}
         P(B_1\cap R_2)+P(B_2\cap R_1) &amp;= P(B_1)P(R_2)+P(B_2)P(R_1) \\
         &amp;= 2\cdot\frac35\cdot\frac25 \\
         &amp;= 2\cdot P(B)P(R) \\
         &amp;= 2\cdot p^1\cdot (1-p)^1
         \end{align}
         $$
      </p>
   </div>
   <p>
      Note, that in Jorki's example $R_1$ and $R_2$ do <em>not</em> refer to different
      balls: the subscripts refer to different <em>draws</em>. Therefore, $R_1$ and $R_2$
      could be the same red ball drawn on turn $1$ and turn $2$.
   </p>
   <p>
      So, having understood this, we can see that to get the total probability
      of $m$ successess (1 blue ball) out of $n$ trials (2 selections), in
      the case where events are
      independent, we are concerned with the number of
      <a href="math_revision.html#combinations_permutations">combintations</a> in
      which the events can occur.
   </p>
   <p>
      The formula for the binomial distribution is...

      $$
      \begin{align}
      P(m\ \text{successes in $n$ independent trials}) &amp;= P(m) \\
      &amp;={_{n}C_m} \cdot p^m \cdot (1-p)^{(n-m)}\\
      &amp;= \frac{n!}{m!(n-m)!} \cdot p^m \cdot (1-p)^{(n-m)}
      \end{align}
      $$

      For $m = 0, 1, \dots, n$.
   </p>
   <p>
   This, incidentally is the same as asking for $P((n-m)\ \text{failures in $n$ independent trials})$ because

      $$
      \begin{align}
      {_{n}C_{(n-m)}} &amp;= \frac{n!}{(n-(n-m))!(n-m)!}\\
      &amp;= \frac{n!}{m!(n-m)!}\\
      &amp;= {_{n}C_m}
      \end{align}
      $$
   </p>
   <p>
      Let's do this to exhaustion... let's imagine another bag. It doesn't
      matter how many blue and red balls are in there, just so long as I can
      select 3 blue balls and 1 red. $P(\text{blue}) = p$ and $P(\text{red}) = (1-p)$.
      Once we've made this selection of 3 blues, 1 red, the question is,
      how many ways were there of getting to this outcome. Now let's check
      our understanding of using combinations (esp. vs. permutations) to get this...
   </p>
   <p>
      We can draw a little outcome tree as follows:
   </p>
   <p>
   <img src="##IMG_DIR##/bayes_bbbr_decision_tree.png"/>
   </p>
   <p>
      Clearly there are 4 ways to arrive at the selection of 3 blues and 1 red,
      once we have made that particular selection. Remember we're not asking
      for a blue/red on a specific turn... we just care about the final
      outcome, irrespective of the order in which the balls were picked.
      And we can see...

      $$
      \begin{align}
      {_4C_3} &amp;= \frac{4!}{3!(4-3)!}
      &amp;= 4
      \end{align}
      $$
   </p>
   <p>
      Why don't we use permutations? The answer is that we don't care if we got
      $B_aB_bB_cR_a$ or $B_bB_aB_cR_a$ or $B_cR_aB_aB_b$ etc etc, where, as before,
      the alphabetical substrcipts distinguish the ball, not the turn on which
      it is drawn as that is given by order of writing.
   </p>
   <p>
      Having gone through this we can then use the formulas for expected value,
      or mean, and variance. To make the notation similar to previous examples
      where we used $P(x)$, in the above formula I just change $m$ for $x$ so
      that we get

      $$
      P(x)= \frac{n!}{x!(n-x)!} \cdot p^x \cdot (1-p)^{(n-x)}
      $$

      Where $x = 0, 1, \dots, n$, meanding that this is the probability of
      $x$ successes out of $n$ trials.
   </p>
   <p>
      Recalling that
      $$
      E(X) = \mu = \sum_x xP(x)
      $$

      We can say that the population mean for the Bernoulli distribution
      is

      $$
      \begin{align}
      E(X) = \mu &amp;= \sum_{x=0}^{x\le n} x \cdot \left(\frac{n!}{x!(n-x)!} \cdot p^x \cdot (1-p)^{(n-x)}\right)
      \end{align}
      $$

      And... the rest of the proof gets a little complicated...
      <a href="http://www.math.ubc.ca/~feldman/m302/binomial.pdf"
         target="_blank">this PDF by Joel Feldman gives the derivation</a>, which
      I found by doing a quick google. Liked the explanation.
   </p>
   <p>
      The population <b>mean</b> and <b>variance</b> are summarised as follows.
      $$
         \begin{align}
            \mu &amp;= E[X] \\
            &amp;= nP\\
                \\
            \sigma_x^2 &amp;= E[(X - \mu)^2] \\
            &amp;= nP(1-P)
         \end{align}
      $$
   </p>
   <p>
      Often when talking about a binomial distribution you will see something like

      $$
      P(X | n = ?, p = ?)
      $$

      This is the binomial distribution for $X$ successes out of $n$ trials
      with the probability of success given by $p$.

   </p>
   <p>
      We can plot some example distributions... lets do this using Python.
   </p>
   <pre  class="prettyprint linenums">import matplotlib.pyplot as pl
import numpy as np
from matplotlib.font_manager import FontProperties
from scipy.stats import binom

fontP = FontProperties()
fontP.set_size('small')

n=50
pLst=[0.1, 0.25, 0.5, 0.75, 0.9]
x = np.arange(-1, n+2)
fig, ax = pl.subplots()

for p in pLst:
   dist = binom(n, p)
   ax.plot(x, dist.pmf(x),linestyle='steps-mid')

ax.legend(['$p={}$'.format(p) for p in pLst],
          ncol = 3,
          prop=fontP,
          bbox_to_anchor=[0.5, 1.0],
          loc='upper center')
fig.show()
fig.savefig('binomial_distrib.png', format='png')</pre>
   <p>
      <img src="##IMG_DIR##/binomial_distrib_example.png"/>
   </p>


   <h3>Poisson Distribution</h3>
   <p>
      Didn't like the starting explanation in [1] so had a look on Wikipedia and
      found a link to the
      <a href="http://www.umass.edu/wsp/resources/poisson/index.html"
         target="_blank">UMass Amherst Uni's stats page on the Poisson distribution</a>
      which I though was really well written. That is the main reference here.
   </p>
   <p>
      Poisson distribution gives the probability of an event occuring some
      number of times in a <em>specific interval</em>. This could be time, distance,
      whatever. What matters is that the <em>interval is specific and fixed</em>.
   </p>
   <p>The example used
      on the UMass Amherst is letters received in a day. The interval here is
      one day. The poisson distribution will then tell you the probability of
      getting a certain number of letters in one day, the <em>interval</em>. Other
      examples could include the number of planes landing at an airport in a day
      or the number of linux server crashes in a year etc...
   </p>
   <p>
      The interval is one component. The other is an already observed average
      rate per interval, or expected number of successes in an interval, $\lambda$.
      For example, we might have observed we get on average 5
      letters per day ($\lambda=5$), or that 1003 planes land at our airport
      ($\lambda=1003$) per day or that there are 4 linux server crashes per year
      ($\lambda=4$) etc...
   </p>
   <p>
      So, poisson has an <em>interval</em> and an observed <em>average count</em>
      for that interval. The following assumptions are made:
   </p>
   <ul>
      <li>The #occurrences can be counted as an integer</li>
      <li>The average #occurrences is known</li>
      <li>The probability of the occurence of an event is constant for all
          subintervals. E.g., if we divided the day into minutes, the probability
          of receiving a letter in any minute of the day is the same as for any
          other minute.</li>
      <li>There can be no more than one occurrence in the subinterval</li>
      <li>Occurrences are independent</li>
   </ul>
   <p>
      The distribution is defined as follows, where $\lambda$ is the expected
      number of events per interval.

      $$
      P(X = x) = \frac{e^{-\lambda}\lambda^x}{x!},\ \ x \ge 0
      $$
   </p>
   <p>
      Eek... didn't like the look of trying to derive the mean and variance.
      The population <b>mean</b> and <b>variance</b> are as follows.

      $$
      \begin{align}
      \mu_x &amp;= E(X) = \lambda\\
      \\
      \sigma^2_x &amp;= E[(X-\mu_x)^2] = \lambda
      \end{align}
      $$
   </p>
   <p>
      We can plot some example distributions... lets do this using Python.
   </p>

   <pre  class="prettyprint linenums">import matplotlib.pyplot as pl
import numpy as np
from matplotlib.font_manager import FontProperties
from scipy.stats import poisson

fontP = FontProperties()
fontP.set_size('small')

expectedNumberOfSuccessesLst = [1, 5, 10, 15]
x = np.arange(-1, 31)
fig, ax = pl.subplots()

for numSuccesses in expectedNumberOfSuccessesLst:
   ax.plot(x, poisson.pmf(x, numSuccesses),linestyle='steps-mid')

ax.legend(['$\lambda={}$'.format(n) for n in expectedNumberOfSuccessesLst],
          ncol = 3,
          prop=fontP,
          bbox_to_anchor=[0.5, 1.0],
          loc='upper center')
fig.show()
pl.show()
fig.savefig('poisson_distrib.png', format='png')</pre>
   <p>
      <img src="##IMG_DIR##/poisson_distrib.png"/>
   </p>
   <p>
      Lets take a little example. Looking at the
      <a href="https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/463045/rrcgb2014-01.pdf"
         target="_blank">UK government report on road casualties in 2014</a>,
      there were a reported 194,477 casualties in 2014. This gives us an
      average of 532.8137 (4dp) casualties per day!
      So, we could ask some questions...
   </p>
   <p>
      What is the probability that <em>no</em> accidents occur on any given
      day? Recalling that...

      $$
         P(X = x) = \frac{e^{-\lambda}\lambda^x}{x!}
      $$

      We will set $\lambda = \frac{194,477}{365}$ and $x = 0$ and plug these
      into the above forumla...
      $$
      \begin{align}
      P\left(X = 0 | \lambda = \frac{194,477}{365}\right) &amp;= \frac{e^{\left(-194,477/365\right)}{\left(\frac{194,477}{365}\right)}^0}{0!}\\
         &amp;= \frac{e^{\left(-194,477/365\right)}\times 1}{1}\\
         &amp;= 3.998994e-232
      \end{align}
      $$

      Okay... so the probability that on any given day in the UK that there are
      no road casualties is pretty (very scarily) small!
   </p>
   <p>
      Of course, we could critisize this analysis as not taking into account
      seaons, or weather conditions etc etc. In winter, for example, when the
      roads are icy one might expect the probability of an accident to be
      greater, but for the purposes of a little example, I've kept it simple.
   </p>
   <p>
      We might also ask, what is the probability that the number of casualties
      is less than, say, 300?
      $$
      P(X \lt 300) = \sum_{x=0}^{299} P(X = x)
      $$

      Eek! Don't really want to be calculating this by hand so let's use
      Python's SciPi package:
   </p>
   <pre class="prettyprint linenums">from scipy.stats import poisson
print poisson.cdf(299, 194477.0/365)</pre>
   <p>This outputs $2.24102710469e-28$ which is still pretty unlikely!.
      For $X \lt 400$ we get $9.60741455596e-10$, for $X \lt 500$
      we get $0.0783182362497$. So we can imagine that the distribution is
      really quite steep:
   </p>
   <pre class="prettyprint linenums">import matplotlib.pyplot as pl
import numpy as np
from scipy.stats import poisson

x = np.arange(200, 800)
fig, ax = pl.subplots()
ax.plot(x, poisson.pmf(x, 194477/365), linestyle='steps-mid')
ax.set_title('Probability of #road casualties per day in UK')
fig.show()
fig.savefig('poisson_road_fatilities_distrib.png', format='png')</pre>
   <p>
   <img src="##IMG_DIR##/poisson_road_fatilities_distrib.png">
   </p>

   <h3>Joint Distributions</h3>
   <p>
      When one thing is likely to vary in dependence on another thing. For
      example, the likely longevity of my milk will correspond to some extent
      to the temperature of my fridge: there is a <em>relationship between
      these two variables so it is important that any model produced includes
      the effect of this relationship</em>. We need to define our
      probabilities that random variables <em>simultaneously</em> take some
      values.
   </p>
   <p>
      Enter the <b>joint probability function</b>. It expresses the probability
      that each random variable takes on a value as a function of those
      variables.
   </p>
   <p>
      A two variable joint probability distribution is defined as:

      $$
         P(x, y) = P(X = x \cap Y = y)
      $$

      This is a subtle difference in the notation of $P(x,y)$ from our
      previous examples in the starting sections where we wrote things like
      $P(A \cap B)$. The former is a distribution where the random variables
      simultaneously take on the values $x$ and $y$ respectively and the latter
      is just the probability of two individual events happening simultaneously.
   </p>
   <p>
      The <b>marginal probabilities</b> are the probabilities that one random
      variable takes on a value regardless of what the other(s) are doing. In
      our two variable distribution we have:

      $$
      \begin{align}
      P(x) &amp;= \sum_y P(x,y) \\
      \\
      P(y) &amp;= \sum_x P(x,y)
      \end{align}
      $$
   </p>
   <p>
      Joint probability functions have these <b>properties</b>:
   </p>
   <ol>
      <li>$0 \le P(x,y) \le 1$ for any pair of values $x$ and $y$,</li>
      <li>The sum of the join probabilities is 1.</li>
   </ol>
   <p>
      The <b>conditional probability function</b> looks like this...
      $$
      \begin{align}
         P(y | x) = \frac{P(x, y)}{P(x)}\\
         \\
         P(x | y) = \frac{P(x, y)}{P(y)}
      \end{align}
      $$
   </p>
   <p>
      The random variables are <b>independent</b> if their joint
      probability function is the product of their marginal probability
      functions:

      $$
      P(x,y) = P(x)P(y) \implies \text{independence}
      $$

      When they are independent we also have

      $$
      \begin{align}
      \text{independence} &amp;\implies P(y | x) = P(y)\ \text{and}\\
                          &amp;\implies P(x | y) = P(x)
      \end{align}
      $$
   </p>
   <p>
      The <b>conditional mean and variance</b> are:

      $$
         \mu_{Y|X} = E[Y|X] = \sum_Y y P(y|x)\ \text{and}\\
         \\
         \mu_{X|Y} = E[X|Y] = \sum_X x P(x|y)
      $$
   </p>

   <h3>Covariance and Correllation</h3>
   <p>
      Measure of joint variablility: the nature and strength of a relationship
      between two variables.
   </p>
   <p>
      <b>Covariance</b> between two random variables $X$ and $Y$ is $Cov(X,Y)$,
      given by:

      $$
         \begin{align}
         Cov(X,Y) &amp;= E[(X-\mu_x)(Y-\mu_y)] \\
                  &amp;= \sum_x\sum_y(x - \mu_x)(y-\mu_y)P(x,y)
         \end{align}
      $$

      This is equivalent to the following:

      $$
         \begin{align}
         Cov(X,Y) &amp;= E[XY] - \mu_x-\mu_y \\
                  &amp;= \sum_x\sum_y xyP(x,y) - \mu_x\mu_y
         \end{align}
      $$

      A covariance that is strongly negative indicates a good inverse <em>linear</em> relationship.
      Strongly positive indicates a good <em>linear</em> relationship and near zero indicates no
      relationship. Note that if two random variables are <b>statistically
      independent</b>, the covariance between them is (near) zero. But, if
      the covariance is (near) zero it does not necessarily mean there is
      no relationship, it might just not be <em>linear</em>.
   </p>
   <p>
      <b>Correlation</b> is just a <em>&quot;normalisation&quot;</em> of the
      covariance such that the measure is limited to being in the range [-1, 1].

      $$
      Corr(X,Y) = \frac{Cov(X,Y)}{\sigma_x\sigma_y}
      $$
   </p>
   <p>
    This YouTube video explains the difference really well:
   </p>
   <iframe width="560" height="315" src="https://www.youtube.com/embed/85Ilb-89sjk?rel=0" frameborder="0" allowfullscreen></iframe>
</div>

<h2>Continuous Distributions</h2>
<div>
   <h3>Cumulative Distribution Function (CDF)</h3>
   <p>
      CDF gives probability that continuous random variable $X$ does not
      exceed a particular value, $x$:

      $$
         CDF(x) = P(X \lt x)
      $$

      The probability that $X$ takes on a signular value is zero. I.e.,
      $P(X == x) = 0$. Therefore, it doesn't matter if we write $\lt$ or
      $\le$...
   </p>
   <p>
      To get the probability that $X$ lies within a range use:

      $$
      \begin{align}
         P(x_1 \lt X \lt x_2) &amp;= CDF(x_2) - CDF(x_1)\\
                              &amp;= P(X \lt x_2) - P(X \lt x_1)
      \end{align}
      $$
   </p>
   <h3>Probability Density Function (PDF)</h3>
   <p>
      Call our PDF $f(x)$... Then the total area under the curve $f(x)$ is 1.
      I.e.,
      $$
         \int_{-\infty}^{\infty} f(x) \mathrm dx = 1.0
      $$

      The probability that $X$ takes a value between two limits is...
      $$
         P(x_1 \lt X \lt x_2) = \int_{x_1}^{x_2} f(x) \mathrm dx
      $$

      And the CDF is also defined by....
      $$
         CDF(x_0) = \int_{min(X)}^{x_0} f(x) \mathrm dx
      $$

      We can judge whether a distribution is a valid PDF using the above
      definitions.
   </p>
   <h3>Uniform Distribution</h3>
   <p>
      The uniform distribution is one where the probability that $X$ takes
      a value in a fixed size interval is the same regardless of where the
      interval &quot;starts&quot; (as long as the interval is contained
      entirely within the range for which $X$ is non-zero). I.e,

      $$
      f(x) =
      \begin{cases}
         \frac{1}{x_u - x_l}, &amp;x_l \le X \le x_u\\[2ex]
         0, &amp;\text{otherwise}
      \end{cases}
      $$
   </p>
   <h3>Normal Distribution</h3>
   <p>
      This distribution is defined by a <a href="gaussians.html">gaussian</a> bell-shaped curve.
      The probability distribution function for a normally distributed random vairable, $X$, is given
      by this equation:

      $$
         f(X = x) = \frac{1}{\sqrt{2\pi\sigma^2}} \cdot e^{-{(x-\mu)^2}/{2\sigma^2}}
      $$

      For any normal distribution the following applies:
   </p>
   <ol><li>About 68% of the data will fall within one standard deviation, $\sigma$, of the mean, $\mu$,</li>
       <li>About 95% of the data will fall within two standard deviations, $2\sigma$, of the mean, $\mu$,</li>
       <li>Over 99% of the data will fall within three standard deviations, $3\sigma$, of the mean, $\mu$,</li>
       <li><b>Mean</b> is $E[X] = \mu$,</li>
       <li><b>Variance</b> is $Var(X) = E[(X - \mu)^2] = \sigma^2$,</li>
   </ol>
   <p>
      The normal distribution is defined with the following <b>notation</b>:
      $$
         X \sim N(\mu, \sigma^2)
      $$
      There is no simple algebraic expression for the cummulative distribution
      function. Can't really say I fancy the idea of integrating the above
      function! There are
      <a href="https://en.wikipedia.org/wiki/Normal_distribution#Numerical_approximations_for_the_normal_CDF"
         target="_blank">many numerical approximations</a>.
      Computer could do it for us, but another way is to <em>convert
      every normal distribution to the standard normal distribution</em>.
   </p>
   <p>
      The <b>standard normal distribution</b> is a normal distribution where
      the the mean is 0 and the variance is 1:

      $$
         Z \sim N(0, 1)
      $$

      And

      $$
         Z = \frac{X - \mu}{\sigma}
      $$

      In English we can say that the <b>z-score/value is the number of standard deviations
      $X$ is away from the (population) mean $\mu$</b>.
    </p>
    <p>
      To solve $P(a \lt X \lt b)$ we solve the following:

      $$
         P\left( \frac{a - \mu}{\sigma} \lt Z \lt \frac{b - \mu}{\sigma}\right)
      $$

      For which we can consult a
      <a href="https://en.wikipedia.org/wiki/Standard_normal_table"
         target="_blank">standard normal table</a>.
   </p>
   <p>
      We can also get the probability of a Z score and vice versa in Python
      by using <code>scipy.stats.norm.cdf()</code> and <code>scipy.stats.norm.ppf()</code>
      respectively as <a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html"
         target="_blank">documented here</a>.
   </p>

   <h4>Percentiles</h4>
   <p>
      <a href="https://en.wikipedia.org/wiki/Percentile"
         target="_blank">Wikipedia defines a percentile</a> as a measure
      giving the value below which a given percentage of obersvations fall. If
      an observation is AT the x<sup>th</sup> percentile then it has the value, V,
      at which x% of the scores can be found. If it is IN this percentile then
      its value is in the range 0 to V.
   </p>
   <p>
      Percentiles aren't really specific to normal distributions but you often
      get asked questions like &quot;what is the 95<sup>th</sup> percentile of
      this distribution?&quot;
   </p>
   <p>
      In the standard normal distribution...
   </p>
   <ol>
      <li>90<sup>th</sup> percentile is at z=1.28. (This is because
          $P(z &lt; 1.28) = 90%$).</li>
      <li>95<sup>th</sup> percentile is at z=1.645. (This is because
          $P(z &lt; 1.645) = 95%$).</li>
      <li>And so on...</li>
   </ol>
</div>

<h2><a name="sampling_distributions">Sampling Distributions</a></h2>
<div>
   <h3>A Little Intro...</h3>
   <p>
      So far we have been talking about <b>population</b> statistics. The
      values $\mu$ and $\sigma$ have been the mean and standard deviation of the
      <b>population</b>. However, generally it is pretty impossible to gather
      information about an entire population: this can be due to the cost that
      would be involved, or perhaps that time that such an endevour would take,
      for example. It might also be undesirable to analyse an entire population
      if, for example, analysis involved destruction of the samples taken!
   </p>
   <p>
      So, what is normally done is to take
      a <b>sample</b> from the population and then <b>use the sample statistics
         to make <em>inferences</em> about the population statistics</b>. The image below
      shows three samples that have been taken from a population. Each sample
      set can, and will most probably, have a different shape, mean, and
      variance!
   </p>
   <p>
      <img src="##IMG_DIR##/sampling_from_a_population.png" alt="Picture of taking different samples from a population and the sample distributions"/>
   </p>
   <p>
      We can demonstrate this concept using a quick little Python program
      to take 4 samples from the normal distribution where each sample
      has 10 members:
   </p>

   <a name="SamplingDistributionPythonExample"></a>
   <pre class="prettyprint linenums">import numpy as np
import matplotlib.pyplot as pl

numSampleSets = 4
numSamplesPerSet = 10

# Limit individual plots, otherwise the first plot takes forever and is rubbish
doShowIndividualSamples = (numSampleSets &lt;= 8) and (numSamplesPerSet &lt;= 50)

# Create a numSampleSets (rows) x numSamplesPerSet (cols) array where we use
# each row as a sample.
randomSamples = np.random.randn(numSampleSets, numSamplesPerSet)

# Take the mean of the rows, i.e. the mean of each sample set
means = randomSamples.mean(axis=1)

if doShowIndividualSamples:
   fig, axs = pl.subplots(nrows=int(numSampleSets/2.0+0.5), ncols=2)
   xticks = np.arange(numSamplesPerSet, dtype='float64')
   for idx in range(numSampleSets):
         ax_col = idx % 2
         ax_row = int(idx/2.0)
         thisAx = axs[ax_row][ax_col]
         thisAx.bar(xticks, randomSamples[idx][:], width=1)
         thisAx.set_xticks(xticks + 0.5)
         thisAx.set_xticklabels(xticks, fontsize=8)
         thisAx.axhline(y=means[idx], color="red", linewidth=2)
         thisAx.set_title("Sample set #{}".format(idx))
         thisAx.grid()

xticks = np.arange(numSampleSets, dtype='float64')
fig2, ax2 = pl.subplots(nrows=2)
ax2[0].bar(xticks, means)
ax2[0].grid()
ax2[0].set_title("Distribution of {} sample means (n={})".format(numSampleSets, numSamplesPerSet))
ax2[0].set_ylabel("Mean value")
ax2[0].set_xlabel("Sample set #")

ax2[1].hist(means, 50)
ax2[1].grid()
ax2[1].set_title("Histogram of {} sample means (n={})".format(numSampleSets, numSamplesPerSet))
ax2[1].set_ylabel("# sample mean's")
ax2[1].set_xlabel("Sample mean bin")

pl.tight_layout()
pl.show()</pre>
   <p>
      The script above produces the following graphs. The x-axis
      is just the sequence number of the sample member and the y-axis the
      value of the sample member. The horizontal line is the sample mean.
   </p>
   <p>
      <img src="##IMG_DIR##/sampling_from_normal_demo_python.png" alt="Graphs of separate samples from normal distribution showing how sample mean varies between samples"/>
   </p>
   <p>
      We can see from this little example that the samples in each of the 4
      instances are different and that the <b>mean is different for each sample</b>.
      Keep in mind that the graph shown when you run the above script will
      be different as it is a random sample :)
   </p>
   <p>
      So we can see that although the <b>population mean is fixed</b> the <b>sample
         mean can vary from sample to sample</b>. Therefore, <b>the mean of a sample is
         itself a random variable</b> and as a random variable it will have it's own
         distribution (same applies for variance).
   </p>
   <p>
      But, we want to use the sample statistics to infer the population statistics.
      How can we do this if the sample mean (and variance) can vary from sample to
      sample? There are a few key statistical theories that will help us out...
   </p>


   <h3><a name="iid">Independent and Identically Distributed (I.I.D.) Random Variables</a></h3>

   <p>
      <a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables"
			target="_blank">Wikipedia</a> says that <q>...a sequence or other collection of random variables is <b>independent and identically distributed (I.I.D.)</b> if <b>each random variable has the same probability distribution as the others</b> and all are <b>mutually independent</b>...</q>
   </p>
   <p>
      It is often the case that if the population is large enough and a sample
      from the population only represents a &quot;small&quot; fraction of the
      population that a set of simple random samples without replacement still
      qualifies I.I.D. selections. If you sample from a population and the sample
      size represents a significant fraction of the population then you
      cannot assume this to be true.
   </p>
   <p>
      We're going to need to know this a little later on when we talk about
      conistentent estimators and the law of large numbers...
   </p>

   <h3><a name="law_of_large_numbers">The Law of Large Numbers</a></h3>
   <p>
      The law of large numbers states that the average of a very large number
      (note we haven't quite defined what &quot;very large&quot; is) of items
      will tend towards the average of the popultion from which the items are
      drawn.  I.e., <b>the sample mean (or any other parameter) tends towards the population mean (or parameter, in general) as the
         number of items in the sample tends to infinity</b>.
   </p>
   <p>
      This is shown empirically in the example below:
   </p>
   <pre class="prettyprint linenums">import numpy as np
import matplotlib.pyplot as pl

maxSampleSizes = [100, 1000, 100000]
fig, axs = pl.subplots(nrows = 3)
for idx, ssize in enumerate(maxSampleSizes):
   sample_sizes = np.arange(1,ssize+1)
   sample_means = np.random.randn(ssize).cumsum() / sample_sizes
   axs[idx].plot(sample_sizes, sample_means)
   axs[idx].set_xlabel("Sample size, max is {}".format(ssize));
   axs[idx].set_ylabel("Average")
   axs[idx].axhline(y=0, color="red")

fig.show(); pl.show()</pre>
   <p>
   Explain the code a little... <code>np.random.randn(ssize)</code> generates a
   numpy array with <code>ssize</code> elements. Each element is a &quot;draw&quot; from
   the standard normal distribution. The function <code>cumsum()</code> then
   produces an array of <code>ssize</code> elements where the second element is
   the sum of the first 2 elements, the third element is the sum of the first 3 elements
   and so on. Thus we have an array where the i<sup>th</sup> element is the
   sum of <code>i</code> samples. Dividing this by the array <code>sample_sizes</code>
   gives us an array of means where the i<sup>th</sup> element is the mean of
   a sample with <code>i</code> items.
   </p>
   <p>
      Running the code produced the figure below...
   </p>
   <p>
      <img src="##IMG_DIR##/stats_law_of_large_numbers.png"/>
   </p>
   <p>
      To summarise, the law of large numbers states that the sample mean of
      I.I.D. samples is consistent with the population mean. The same is
      true for sample variance. I.e., as the number of items in the sample increases
      indefinitely, the sample mean will become a better and better estimate of the
      population mean.
   </p>


   <h3><a name="SamplingDistributions">Sampling Distribution Of The Sample Mean</a></h3>
   <p>
      We've established that between samples, the mean and variance of the
      samples, well... varies! This implies that we can make a <b>distribution
      of sample means</b>.
   </p>
   <p>
      The <b>&quot;sampling distribution of the sample mean&quot;</b> (a bit of a mouthful!)
      is the probability
      distribution of the sample means obtained from all possible samples
      of the same number of observations.
    </p>
    <p>That's a bit of a mounthful! What it
      means is that if we took, from the population, the exhaustive set of all
      distinct samples of size $n$, and then took the mean of each sample, we could
      figure out what the propability is that any sample of size $n$ has a
      specific mean. Thus we build up the probability distribution of sample
      means, where the sample size is $n$. We will see that this probability distribution
      is centered around the mean of all the sample means and that
      it also has a normal distribution (see LLN and CLT).
   </p>
   <p>
      For example if I am a factory owner and I produce machines that accurately
      measure distance, I could have a population of millions. I clearly do not
      want to test each and every device coming off my production line, especially
      if the time that testing requires is anything approaching the time taken to
      produce the item: I'd be halving (or more) my production throughput!
   </p>
   <p>
      So what do I do? I can take a sample of say 50 devices each day. I can
      test these to see if they accurately measure distance, and if they do I can
      assume the production process is still running correctly.
   </p>
   <p>
      But as we have seem if I test 50 devices each day for 10 days, each of my
      10 sample sets will have a different mean accuracy. On the first day, the
      mean accuracy of 50 devices might be 95%, on the second day, the mean of
      the next 50 devices might be 96.53% and so on.
   </p>
   <p>
      The sample mean has a distribution. As we can take many samples from
      a population we have sampled the sample mean, so to speak, hence the
      rather verbose title &quot;sampling distribution of the sample mean&quot;.
   </p>
   <p>
      Now, I can ask, on any given day, &quot;what is the probability that the
      mean accuracy of my 50 devices is, say 95%?&quot;. This is the sampling distribution
      of the sample mean: the probability
      distribution of the sample means (mean accuracy of a sample of devices) obtained
      from all possible samples (theoretical: we can't actually measure all possible samples!)
      of the same number of observations (50 in this case).
   </p>
   <p>
      The law of large numbers gives us a little clue as to how variable the
      sample means will be... we know that if the sample size is large then
      the sample mean tends towards the population mean as has a much narrower
      variance about the population mean. So, 50 samples is better than 10.
      But 10,000 samples would be even better. The question is how many samples
      do we need. Will try to answer that (much) later on...
   </p>

   <h4>Sample Mean And It's Expected Value (The Mean Of Sample Means)</h4>
   <p>
      Continuing with the example of distance measurement devices. We could
      say each device in our sample set is represented by random variables
      $A_1, A_2, ..., A_{50}$ (we samples 50 devices each day).
      We can generalise this to $m$ devices in the
      sample set.

      Using our definition of <a href="#def_expected_value">expected value</a>
      we can define the <b>sample mean</b> as the random variable $\overline A_i$,
      for the  i<sup>th</sup> sample set of, and is defined as follows.

      $$
      \overline X_i = \frac{1}{m}\sum_{i=1}^m A_i
      $$

    </p>
    <p>
      Now we can calculate the <em>expected value of the sample mean</em>, $E(\overline X)$
      (the mean of the sample means).
    </p>
    <p>
      Imagine that
      we take $n$ samples, where each sample is a set of $m$ devices from our
      population. If we represent the mean of each sample as the random variables
      $\overline X_1, \overline X_2, \cdots, \overline X_n$, then the expected
      value of the distribution of sample means
      is the mean expected value of the samples...

      $$
      E(\overline X) = E\left(\frac{1}{n}(\overline X_1 + \overline X_2 + \cdots + \overline X_n)\right)
      $$

      We saw that <a href="#linear_functions_of_x">expected value of a linear combination
         of random variables</a> is the linear combination of each random variable's
      expected value. This means that we can write the following.

      $$
      E(\overline X) = \frac{1}{n}\left[E(\overline X_1) + E(\overline X_2) + \cdots + E(\overline X_n)\right]
      $$

      The <a href="#law_of_large_numbers">law of large numbers</a> also tells us
      that if the size of each sample
      is sufficiently large, it's sample mean, $\overline{X_i}$ will tend
      towards the population mean, $\mu$. So, if $m$ is large enough we can say...

      $$
      \begin{align}
      E(\overline X) &amp;= \frac{1}{n}\left[\mu + \mu + \cdots + \mu\right]\\
      &amp;= \frac{n\mu}{n}\\
      &amp;= \mu
      \end{align}
      $$for the

      This means that the <b>mean of &quot;the sample distribution of sample means&quot;
      is the population mean</b> when the size of each sample ($m$) is sufficiently
   large. Put another way, <b> the distribution of samples means in centred
      around the population mean</b>.
   </p>
   <p>
      A single sample mean can therefore be larger or smaller than the population
      mean, but on average, there isn't any reason to expect that it is either. As
      the sample size increases we also know that the likelihood of the sample
      mean being higher or lower than the population mean decreases (law
      of large numbers).
   </p>
   <h4>The Variance Of The Sample Mean w.r.t. Sample Size And Standard Error</h4>
   <p>
      Sample
      variance can be written as $\sigma_{\overline X}^2$ or $S^2$.

      $$
      \text{Var}(\overline X) = \sigma_{\overline X}^2 = S^2 = \frac{\sigma^2}{n}
      $$

      We can see that <b>variance of the sampling distribution decreases as sample size
         increases.</b> Therefore the larger the sample the more accurately we can
      infer population statistics.
   </p>
   <p>
      How did we get the above results? Well, it all is a bit brain melting, but
      here goes. The variance of the mean of sample means is written as $\text{Var}(\overline X)$.
      Because it is the variance of the mean of sample means, we can write this:

      $$
         \text{Var}(\overline X) = \text{Var}\left(\frac{1}{n} \sum_{i=1}^{i \le n} \overline X_i\right)
      $$

      The constant $n$ can be taken out of the variance. TODO - finish this off.
   </p>
   <p>
      The sample standard deviation is often refered to as the <b>standard error</b>.

      $$
      \text{Standard error} = \sigma_{\overline X} = \frac{\sigma}{\sqrt n}
      $$

      If sample size not super small compared to population use <b>finite population correction factor</b>
      $\frac{N-n}{N-1}$ to get

      $$
      \text{Var}(\overline X) = \frac{\sigma^2}{n} \cdot \frac{N-n}{N-1}
      $$
   </p>
   <h4>The Shape Of The Samplign Distribution Of Sample Means</h4>
   <p>
      When samples are selected from a population that has a normal distribution
      we will see (anecdotally) that the sampling distribution of sample means
      is also normally distributed.
   </p>
   <p>
      A histogram of the sample means gives a better picture of the
      distribution of sample means from the 4 sample sets. Diagrams have been
      drawn using the <a href="#SamplingDistributionPythonExample">previous python example</a>.
   </p>
   <p>
      <img src="##IMG_DIR##/sampling_from_normal_demo_python_dist.png" alt="Graphs of separate samples from normal distribution showing how sample mean varies between samples"/>
   </p>
   <p>
      Now observe what happens when we increase the number of sample sets taken to 50.
      The distribution of sample means is still pretty distributed without much definition of the shape of the distribution...
   </p>
   <p>
      <img src="##IMG_DIR##/sampling_from_normal_demo_python_dist_50.png" alt="Graphs of separate samples from normal distribution showing how sample mean varies between samples"/>
   </p>
   <p>
      Now observe what happens when we increase the number of sample sets taken to 1000.
      The distribution of sample means begins to take shape...
   </p>
   <p>
      <img src="##IMG_DIR##/sampling_from_normal_demo_python_dist_1000.png" alt="Graphs of separate samples from normal distribution showing how sample mean varies between samples"/>
   </p>
   <p>
      Now observe what happens when we increase the number of sample sets taken to 1000.
      The distribution of sample means now really looks very much like a gaussian distribution... interesting!
   </p>
   <p>
      <img src="##IMG_DIR##/sampling_from_normal_demo_python_dist_10000.png" alt="Graphs of separate samples from normal distribution showing how sample mean varies between samples"/>
   </p>
   <p>
      Clearly when we sample from the population the sample can be, to varying
      degrees, either a good or bad representation of the population. To help
      ensure that that sample represents the population (i.e., no &quot;section&quot;
      of the population is over or under represented) a <b>simple random sample</b>
      is usually taken.
   </p>
   <p>
      Also of great interest in the above is that as the number of samples
      taken increases the distribution of sample means appears to become more
      and more gaussian in shape!. What is always true, and even more important is that <b>the
      sampling distribution becomes concentrated closer to the population mean
      as the sample size increases</b>, as we have seen in the maths earlier.
      The example above also doesn't
      proove it... its just anecdotal evidence. We could also notice that
      <b>as #samples increases the variance of the sample mean decreases</b>,
      again as we saw in the maths earlier.
   </p>
   <p>
      Remember: take care to differentiate between the <b>sample mean, $\overline x$</b>,
      sometimes witten as $\mu_{\overline X}$,
      and the <b>population mean, $\mu$</b>. We do not know the population
      mean. We know the sample mean. The population mean is fixed. The sample mean,
      as seen, will vary between samples.
   </p>
   <p>
      We must also remember to differentiate between the <b>sample variance, $\sigma_{\overline X}^2$</b>
      and the <b>population variance, $\sigma^2$</b>.
      We do not know the population variance. We know the sample mean.
      The population variance is fixed. The sample variance,
      as seen, will vary between samples.
   </p>
   <p>
      Also remember that the samples were drawn from a population that is
      normally distributed. So the sampling distribution was also normally
      distributed, as we have anacdotally seen. The central limit theory (CLT)
      will show us that is doesn't matter what the population distriution is.
      Enough samples and the sampling distribution of the sample mean will always
      tend towards normal distribution.
   </p>
   <p>
      Because the sampling distribution of sample means is normally distributed,
      it means that we can also form a <b>standard normal distribution for the
         sample means</b>, which we do as follows:

      $$
      \begin{align}
         Z &amp;= \frac{\overline X - \mu}{\sigma_{\overline X}} \\
         &amp;= \frac{\overline X - \mu}{\frac{\sigma}{\sqrt n}}
      \end{align}
      $$
   </p>

   <h3><a name="CentralLimit">Central Limit</a></h3>
   <p>
      We saw that the mean of the sampling distribution of sample means is
      $E(\overline X) = \mu$ and that the variance of the sample mean is
      $\text{Var}(\overline X) = \frac{\sigma^2}{n}$. We also know (although
      I haven't shown this... I haven't bothered looking up the proof either!)
      that the sampling distribution of sample means is also normal.
   </p>
   <p>
      The central limit theorem removes the restriction that the population we
      draw from need be normally distributed in order for the sampling distribution
      of the sample mean to be normally distributed. The central limit theoem
      states that <b>the mean of a random sample drawn from a population with
         <em>any</em> distribution will be approx. normally distributed as the
      number of samples, $n$, becomes large</b>.
   </p>
   <p>
      We could test this for, say, samples drawn from the binomial
      distribution. We have to modify our python code a little though (and
      also slim line some of the bits out)...
   </p>
   <pre class="prettyprint linenums">import numpy as np
import matplotlib.pyplot as pl

numSampleSets = 4000
numSamplesPerSet = 10
p = 0.5

# Make an array of numSampleSets means of samples of size numSamplesPerSet
# drawn from the binomial distirbution with prob of success `p`
means = np.random.binomial(numSamplesPerSet, p, numSampleSets)
means = means.astype("float64") / numSamplesPerSet

xticks = np.arange(numSampleSets, dtype='float64')
fig2, ax2 = pl.subplots()
ax2.hist(means, 50)
ax2.grid()
ax2.set_title("Histogram of {} sample means (n={})\nSamples draw from binomian p={}".format(numSampleSets, numSamplesPerSet, p))
ax2.set_ylabel("# sample mean's")
ax2.set_xlabel("Sample mean bin")

pl.tight_layout()
pl.show()</pre>
   <p>
      When we set the number of sample sets taken to be small, at 10,
      we get this:
   </p>
   <p>
   <img src="##IMG_DIR##/dist_sample_means_from_binom_10_demo_python.png"/>
   </p>
   <p>
      When we set the number of sample sets taken to be very large, at 4000,
      we get this:
   </p>
   <p>
   <img src="##IMG_DIR##/dist_sample_means_from_binom_4000_demo_python.png"/>
   </p>
   <p>
      Hmmm... anacdotally satisfying at least.
   </p>
</div> <!-- END sampling distributions -->


<h2>Confidence Intervals</h2>
<div>
   <p>The following is mostly based
      on <a href="https://www.khanacademy.org/math/probability/statistics-inferential/confidence-intervals/v/confidence-interval-1"
         target="_blank">this Khan Achademy tutorial</a> with some additions
      from my reference textbook.
   </p>

   <p>
      A confidence interval is a range of values which we are X% certain contain
      an unknown population parameter (e.g. the population mean), based
      on information we obtain from a sample. In other words, we can <em>infer
      from our sample something about an <b>unknown</b> population parameter</em>.
   </p>

   <p>
      Let's go back to our distance measurement devices. I have a test
      fixture that is exactly 100cm wide. Therefore a device should, when placed
      in this fixture, report/measure a distance of 100cm +/- some tolerance.
   </p>

   <p>
      Remember that I don't want to test all of the sensors I've produced
      because this will kill the manufacturing time and significantly raise
      the cost per unit. So I've decide to test, let's say, 50 sensors.
   </p>

   <p>
      As I test each device in my sample of 50 I will get back a set of
      test readings, one for each device. 100.1cm, 99cm, 99.24cm, ... etc. From
      the sample I can calculate sample mean and sample variance. But this is
      about all I know: I do not know my population mean or population variance!
   </p>

   <p>
      But I have learn't something about the sampling distribution of sample means.
      To recap, we have seen that:

      $$
         E(\overline X) = \mu
      $$

      The expected value of the sample mean (i.e.,
      the mean of all possible sample means) is the same as the population mean
      for large enough samples.

      $$
         \text{Var}(\overline X) = \frac{\sigma^2}{n}
      $$

      The variance of the sample mean is related to the poulation variance by
      sample size.
   </p>

   <p>
      So, I also know that my specific sample mean must lie somewhere in the
      sampling distribution of sample means...
   </p>

   <p>
      Continuing with the example then... let's say I have taken my sample
      of 50 devices. I have a sample mean of $\overline x = 105\text{cm}$. This
      is shown in the graph of the sampling distribution of sampling means below.
      In this distribution my specific sample has a mean that lies somewhere in this
      distribution.
   </p>

   <p>
      <img src="##IMG_DIR##/confidence_interval_illustration.png"/><br>
      <span id="confidence_interval_illustration_code_link" style="font-size:10pt;" href="">&lt;Click me to toggle code view for graph creation&gt;</span>
   </p>

   <pre class="prettyprint linenums" id="confidence_interval_illustration_code_p">import matplotlib.pyplot as pl
import numpy as np
import scipy.stats

sample_mean = 105
population_mean = 99
expected_sample_mean = 102
var_of_expected_sample_mean = 4
std_of_expected_sample_mean = np.sqrt(var_of_expected_sample_mean)

x = np.linspace( expected_sample_mean - 4 * var_of_expected_sample_mean
               , expected_sample_mean + 4 * var_of_expected_sample_mean
               , 500)
y = scipy.stats.norm.pdf( x
                        , loc   = expected_sample_mean
                        , scale = var_of_expected_sample_mean)

max_y = scipy.stats.norm.pdf( expected_sample_mean
                            , loc   = expected_sample_mean
                            , scale = var_of_expected_sample_mean)

fig, ax = pl.subplots()
ax.plot(x,y)
fill_mask = (x &gt;= expected_sample_mean) &amp; (x &lt;= expected_sample_mean + std_of_expected_sample_mean)
ax.fill_between(x, 0, y
               , where       = fill_mask
               , interpolate = True
               , facecolor   = 'lightblue')

ax.annotate(r'$E(\overline{X}) = \mu$',
            xy=(expected_sample_mean, 0),
            xytext=(expected_sample_mean-2*var_of_expected_sample_mean, 0.02),
            bbox=dict(fc="w"),
            fontsize='large',
            arrowprops=dict(facecolor='black', shrink=0.05, connectionstyle="arc3,rad=0.2", fc="w"))


ax.annotate(''
      , xy=(expected_sample_mean, max_y/2)
      , xytext = (expected_sample_mean + std_of_expected_sample_mean, max_y/2)
      , arrowprops=dict(arrowstyle="&lt;-&gt;"
                       , connectionstyle="arc3"
                       )
      )

ax.annotate(r'$\sigma_{\overline{X}} = \frac{\sigma}{\sqrt{n}}$',
            xy=(expected_sample_mean + std_of_expected_sample_mean/2, max_y/2),
            xytext=(expected_sample_mean + 2*std_of_expected_sample_mean, 3*max_y/4),
            fontsize='large',
            bbox=dict(fc="w"),
            arrowprops=dict(facecolor='black', shrink=0.05, connectionstyle="arc3,rad=0.2", fc="w"))


ax.axvline(x=population_mean, color='black', lw=2)
ax.annotate('Population mean, $\\mu$,\nis unknown!',
            xy=(population_mean, max_y/2),
            xytext=(x[0], 3*max_y/4),
            bbox=dict(fc="w"),
            arrowprops=dict(facecolor='black', shrink=0.05, connectionstyle="arc3,rad=0.2", fc="w"))

ax.axvline(x=sample_mean, color='black', lw=2)
ax.annotate('Sample mean, $\\overline{{x}}$,\nis {}'.format(sample_mean),
            xy=(sample_mean, max_y/2),
            xytext=(sample_mean + 2*std_of_expected_sample_mean, max_y/4),
            bbox=dict(fc="w"),
            arrowprops=dict(facecolor='black', shrink=0.05, connectionstyle="arc3,rad=0.2", fc="w"))

ax.set_title("An example sampling distribution of sample means\nfor the distance measurement devices")
ax.grid()
pl.show()</pre>

   <p>
      The graph above also shows the population mean. This also lies somewhere in
      this distribution of sample means, but we don't know where. <em>This is
         the parameter that we want to infer!</em>
      The single sample's mean and variance are all we have at the moment so
      somehow we need to move from these statistics to an assertion about
      the population mean.
   </p>
   <p>
      Now I'm going to stop talking about $\overline x$, our specific sample
      mean. This is because we are taking about <em>any</em> sample, so we want
      to use a random variable that represents the mean of a random sample,
      $\overline X$.
   </p>
   <p>
      We know $\overline X$ is somwhere near $E(\overline X)$ and will lie in
      an interval that spans the distance $E(\overline X) \pm \text{interval}$.
      But how big is this interval? To be certain that it contains our sample
      mean it would have to be infinitely wide! So we can't be certain. But, we
      could be pretty certain. We could, for example, say we'd be satisfied if
      we were 95% certain that $\overline X \in E(\overline X) \pm \text{interval}$...
      In other words we are asking the following question, what is...

      $$
         P(E(\overline X) - \text{interval/2} \lt \overline X \lt  E(\overline X) + \text{interval/2}) = 0.95\ ??
      $$

      This interval that gives us a 95% probability that the mean of a random
      sample (of size 50 in this case) will lie within $\text{interval}$ of
      the expected sample mean. (It doesn't have to be 95%, you choose how
      confident you want to be!).
   </p>

   <p>
      Hang on! We know from the CLT that the sampling distribution should be
      normal. So we can figure this out using the normal distribution. Further
      more we know that we can normalise the distribution to arrive at the
      standard normal distribution. Therefore, what we are looking for in the
      standard normal is the following:
   </p>
   <p>
      <img src="##IMG_DIR##/conf_z_95p.png"/><br>
      <span id="z_confidence_interval_illustration_code_link" style="font-size:10pt;" href="">&lt;Click me to toggle code view for graph creation&gt;</span>
   </p>

   <pre class="prettyprint linenums" id="z_confidence_interval_illustration_code_p">import matplotlib.pyplot as pl
import numpy as np
import scipy.stats


z = np.linspace(-4, 4, 500)
y = scipy.stats.norm.pdf(z)
x_95p = scipy.stats.norm.ppf(0.975) #.025 in each tail gives 0.05 for 95% conf
x95_mid = scipy.stats.norm.ppf(0.9875)

fig, ax = pl.subplots()
ax.plot(z,y)
ax.fill_between(z, 0, y
               , where       = z &lt; -x_95p
               , interpolate = True
               , facecolor   = 'lightblue')
ax.text(-x_95p, -0.02, "$-{0:.3f}z$".format(x_95p), ha="center", fontsize='large')

ax.fill_between(z, 0, y
               , where       = z &gt; x_95p
               , interpolate = True
               , facecolor   = 'lightblue')
ax.text(x_95p, -0.02, "${0:.3f}z$".format(x_95p), ha="center", fontsize='large')

ax.plot( [0, 0], [0, max(y)], color='b')
ax.text(0, -0.02, "$0$", ha="center", fontsize='large')

ax.annotate( "0.025"
           , xy=(x95_mid, scipy.stats.norm.pdf(x95_mid)/2)
           , xytext=(40, 40)
           , textcoords='offset points'
           , bbox=dict(fc="lightblue")
           , fontsize='large'
           , arrowprops=dict(facecolor='black', shrink=0.05, connectionstyle="arc3,rad=0.2", fc="w"))

ax.annotate( "0.025"
           , xy=(-x95_mid, scipy.stats.norm.pdf(-x95_mid)/2)
           , xytext=(40, 40)
           , textcoords='offset points'
           , bbox=dict(fc="lightblue")
           , fontsize='large'
           , arrowprops=dict(facecolor='black', shrink=0.05, connectionstyle="arc3,rad=0.2", fc="w"))

ax.annotate( "0.95"
           , xy=(0, max(y)/2.0)
           , xytext=(40, 40)
           , textcoords='offset points'
           , bbox=dict(fc="w")
           , fontsize='large'
           , arrowprops=dict(facecolor='black', shrink=0.05, connectionstyle="arc3,rad=0.2", fc="w"))

ax.set_xticks([])
ax.set_yticks([])
ax.set_title("95% confidence interval ~ N(0,1)")
pl.show() </pre>


   <p>
      And we previously saw how to do this:

      $$
         Z = \frac{\overline X - \mu}{\frac{\sigma}{\sqrt n}}
      $$

      Apply this to the interval

      $$
         P(E(\overline X) - \text{interval/2} \lt \overline X \lt  E(\overline X) + \text{interval/2}) = 0.95
      $$

      Will give us

      $$
      \begin{align}
         0.95 &amp;= P(-\text{normalised interval/2} \lt Z \lt \text{normalised interval/2}) \\
         &amp;= P(-\text{normalised interval/2} \lt \frac{\overline X - \mu}{\frac{\sigma}{\sqrt n}} \lt \text{normalised interval/2})
      \end{align}
      $$

      And we know how to calculate this &quot;normalised interval&quot; It is
      the Z value that will give us the 95% condifence interval we see above,
      and this Z value is, by consulting tables, 1.96.

      $$
      \begin{align}
      0.95 &amp;= P(-1.96 \lt \frac{\overline X - \mu}{\frac{\sigma}{\sqrt n}} \lt 1.96)
      \end{align}
      $$

      Re-arange this a little...

      $$
      \begin{align}
      0.95 &amp;= P(-1.96 \lt \frac{\overline X - \mu}{\frac{\sigma}{\sqrt n}} \lt 1.96) \\
           &amp;= P(-1.96\cdot \frac{\sigma}{\sqrt n} \lt \overline X - \mu \lt 1.96\cdot \frac{\sigma}{\sqrt n})  \\
           &amp;= P(-1.96\cdot \frac{\sigma}{\sqrt n} - \overline X \lt - \mu \lt 1.96\cdot \frac{\sigma}{\sqrt n} - \overline X) \\
           &amp;= P(\overline X + 1.96\cdot \frac{\sigma}{\sqrt n} \gt \mu \gt \overline X - 1.96\cdot \frac{\sigma}{\sqrt n} ) \text{  (multiply by -1 reverses inequalities)}\\
           &amp;= P(\overline X - 1.96\cdot \frac{\sigma}{\sqrt n} \lt \mu \lt \overline X + 1.96\cdot \frac{\sigma}{\sqrt n} ) \\
      \end{align}
      $$

      And... oh! I know my sample mean. Lets say it was 99.5cm... then I have
      $$
      \begin{align}
      0.95 &amp;= P(99.5 - 1.96\cdot \frac{\sigma}{\sqrt n} \lt \mu \lt 99.5 + 1.96\cdot \frac{\sigma}{\sqrt n} )
      \end{align}
      $$

      Ah crap, I don't know the population standard deviation. But I do know my
      sample standard deviation. If my sample size is large enough the LLN says
      it will be a consistent estimator of the population standard deviation. So
      we'll approximate and say...

      $$
      \begin{align}
      0.95 &amp;= P(99.5 - 1.96\cdot \frac{s}{\sqrt n} \lt \mu \lt 99.5 + 1.96\cdot \frac{s}{\sqrt n} )
      \end{align}
      $$

      Okay, lets say my sample had a standard deviation of 0.5cm. Then we get...

      $$
      \begin{align}
      0.95 &amp;= P(99.5 - 1.96\cdot \frac{0.5}{\sqrt{50}} \lt \mu \lt 99.5 + 1.96\cdot \frac{0.5}{\sqrt{50}} )
      \end{align}
      $$

      Well this is great, we now know that the population mean is somewhere
      in the interval $99.5 \pm 1.96\cdot \frac{0.5}{\sqrt{50}}$ with a
      95% confidence! I.e. we are 95% confident that the population
      mean lies somewhere between 99.35cm and 99.64cm. So we can conclude that
      our production process is producing instruments that slightly underestimate
      distance.
   </p>
   <p>
      Quite a few assumptions and estimates have been made here. I assumed that
      I could estimate the population standard deviation with my sample's
      standard deviation. This could be okay for large sample sizes from an
      even larger population, but when this is not the case, this assumption
      breaks down. Something called the &quot;Student-t&quot; distribution will
      cope with this and we'll come to that later.
   </p>

</div> <!-- END Confidence intervals -->

<h2>Kalman Filter</h2>
<div>
<pre>ttp://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/</pre>
</div>

</div>
</div>
</body>
</html>
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
